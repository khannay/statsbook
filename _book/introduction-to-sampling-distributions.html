<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 9 Introduction to Sampling Distributions | Introduction to Statistics and Data Science</title>
  <meta name="description" content="Introductory textbook for statistics and data science" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 9 Introduction to Sampling Distributions | Introduction to Statistics and Data Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Introductory textbook for statistics and data science" />
  <meta name="github-repo" content="khannay/statsbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 9 Introduction to Sampling Distributions | Introduction to Statistics and Data Science" />
  
  <meta name="twitter:description" content="Introductory textbook for statistics and data science" />
  

<meta name="author" content="Dr. Kevin Hannay" />


<meta name="date" content="2023-02-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="continuous-random-variables.html"/>
<link rel="next" href="confidence-intervals.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="font-awesome.min.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> Stats Notes </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#librarian-or-farmer"><i class="fa fa-check"></i><b>1.1</b> Librarian or Farmer?</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#profits"><i class="fa fa-check"></i><b>1.2</b> Profits</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#accidental-deaths"><i class="fa fa-check"></i><b>1.3</b> Accidental Deaths</a></li>
</ul></li>
<li class="part"><span><b>I Exploratory Data Analysis</b></span></li>
<li class="chapter" data-level="2" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i><b>2</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#what-is-r"><i class="fa fa-check"></i><b>2.1</b> What is R?</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#r-packages"><i class="fa fa-check"></i><b>2.2</b> R Packages</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#r-as-a-fancy-calculator"><i class="fa fa-check"></i><b>2.3</b> R as a Fancy Calculator</a></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#more-advanced-r"><i class="fa fa-check"></i><b>2.4</b> More Advanced R</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#data-types-in-r"><i class="fa fa-check"></i><b>2.4.1</b> Data Types in R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-r.html"><a href="introduction-to-r.html#logic-in-r"><i class="fa fa-check"></i><b>2.5</b> Logic in R</a></li>
<li class="chapter" data-level="2.6" data-path="introduction-to-r.html"><a href="introduction-to-r.html#storing-data-in-r"><i class="fa fa-check"></i><b>2.6</b> Storing Data in R</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#vectors"><i class="fa fa-check"></i><b>2.6.1</b> Vectors</a></li>
<li class="chapter" data-level="2.6.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#data-frames"><i class="fa fa-check"></i><b>2.6.2</b> Data Frames</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introduction-to-r.html"><a href="introduction-to-r.html#basic-plots-in-r"><i class="fa fa-check"></i><b>2.7</b> Basic Plots in R</a></li>
<li class="chapter" data-level="2.8" data-path="introduction-to-r.html"><a href="introduction-to-r.html#additional-resources"><i class="fa fa-check"></i><b>2.8</b> Additional Resources</a></li>
<li class="chapter" data-level="2.9" data-path="introduction-to-r.html"><a href="introduction-to-r.html#homework"><i class="fa fa-check"></i><b>2.9</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>3</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#shot-logs-basketball-data"><i class="fa fa-check"></i><b>3.1</b> Shot Logs Basketball Data</a></li>
<li class="chapter" data-level="3.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#principal-types-of-statistical-data"><i class="fa fa-check"></i><b>3.2</b> Principal Types of Statistical Data</a></li>
<li class="chapter" data-level="3.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#the-distribution-of-a-data-set"><i class="fa fa-check"></i><b>3.3</b> The Distribution of a Data Set</a></li>
<li class="chapter" data-level="3.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#numerical-measures-for-central-tendency"><i class="fa fa-check"></i><b>3.4</b> Numerical Measures for Central Tendency</a></li>
<li class="chapter" data-level="3.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#numerical-measures-of-variability"><i class="fa fa-check"></i><b>3.5</b> Numerical Measures of Variability</a></li>
<li class="chapter" data-level="3.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#numerical-measures-for-relative-standing"><i class="fa fa-check"></i><b>3.6</b> Numerical Measures for Relative Standing</a></li>
<li class="chapter" data-level="3.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#relation-between-continuous-and-categorical-variables-boxplot"><i class="fa fa-check"></i><b>3.7</b> Relation between Continuous and Categorical Variables: Boxplot</a></li>
<li class="chapter" data-level="3.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#relation-between-continuous-variables-scatter-plots"><i class="fa fa-check"></i><b>3.8</b> Relation between Continuous Variables: Scatter Plots</a></li>
<li class="chapter" data-level="3.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#relationship-between-categorical-variables-contingency-tables"><i class="fa fa-check"></i><b>3.9</b> Relationship between Categorical Variables: Contingency Tables</a></li>
<li class="chapter" data-level="3.10" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#tips-and-tricks"><i class="fa fa-check"></i><b>3.10</b> Tips and Tricks</a></li>
<li class="chapter" data-level="3.11" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#homework-1"><i class="fa fa-check"></i><b>3.11</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-wrangling.html"><a href="data-wrangling.html#what-is-data-wrangling"><i class="fa fa-check"></i><b>4.1</b> What is Data Wrangling?</a></li>
<li class="chapter" data-level="4.2" data-path="data-wrangling.html"><a href="data-wrangling.html#nas-and-the-curse-of-real-world-data"><i class="fa fa-check"></i><b>4.2</b> NA’s and the Curse of Real World Data</a></li>
<li class="chapter" data-level="4.3" data-path="data-wrangling.html"><a href="data-wrangling.html#select-pick-only-a-few-columns"><i class="fa fa-check"></i><b>4.3</b> Select: Pick only a few columns</a></li>
<li class="chapter" data-level="4.4" data-path="data-wrangling.html"><a href="data-wrangling.html#filter-select-rows"><i class="fa fa-check"></i><b>4.4</b> Filter (select rows)</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="data-wrangling.html"><a href="data-wrangling.html#compound-criteria"><i class="fa fa-check"></i><b>4.4.1</b> Compound Criteria</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="data-wrangling.html"><a href="data-wrangling.html#chainspipes"><i class="fa fa-check"></i><b>4.5</b> Chains/Pipes %&gt;%</a></li>
<li class="chapter" data-level="4.6" data-path="data-wrangling.html"><a href="data-wrangling.html#grouping-data-together"><i class="fa fa-check"></i><b>4.6</b> Grouping Data Together</a></li>
<li class="chapter" data-level="4.7" data-path="data-wrangling.html"><a href="data-wrangling.html#homework-2"><i class="fa fa-check"></i><b>4.7</b> Homework</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="data-wrangling.html"><a href="data-wrangling.html#concept-questions-2"><i class="fa fa-check"></i><b>4.7.1</b> Concept Questions</a></li>
<li class="chapter" data-level="4.7.2" data-path="data-wrangling.html"><a href="data-wrangling.html#practice-problems-2"><i class="fa fa-check"></i><b>4.7.2</b> Practice Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html"><i class="fa fa-check"></i><b>5</b> Introduction to Clustering</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#what-is-clustering"><i class="fa fa-check"></i><b>5.1</b> What is Clustering?</a></li>
<li class="chapter" data-level="5.2" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#introduction-to-kmeans-clustering"><i class="fa fa-check"></i><b>5.2</b> Introduction to Kmeans clustering</a></li>
<li class="chapter" data-level="5.3" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#how-many-clusters-should-we-choose"><i class="fa fa-check"></i><b>5.3</b> How many clusters should we choose?</a></li>
<li class="chapter" data-level="5.4" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#clustering-nba-players"><i class="fa fa-check"></i><b>5.4</b> Clustering NBA Players</a></li>
<li class="chapter" data-level="5.5" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#requirements-for-performing-cluster-analysis"><i class="fa fa-check"></i><b>5.5</b> Requirements for Performing Cluster Analysis</a></li>
<li class="chapter" data-level="5.6" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#homework-3"><i class="fa fa-check"></i><b>5.6</b> Homework</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#concept-questions-3"><i class="fa fa-check"></i><b>5.6.1</b> Concept Questions</a></li>
<li class="chapter" data-level="5.6.2" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#practice-problems-3"><i class="fa fa-check"></i><b>5.6.2</b> Practice Problems</a></li>
<li class="chapter" data-level="5.6.3" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#advanced-problems-3"><i class="fa fa-check"></i><b>5.6.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Probability Theory</b></span></li>
<li class="chapter" data-level="6" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>6</b> Probability</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability.html"><a href="probability.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>6.1</b> Sample Spaces and Events</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="probability.html"><a href="probability.html#introduction"><i class="fa fa-check"></i><b>6.1.1</b> Introduction</a></li>
<li class="chapter" data-level="6.1.2" data-path="probability.html"><a href="probability.html#sample-spaces"><i class="fa fa-check"></i><b>6.1.2</b> Sample Spaces</a></li>
<li class="chapter" data-level="6.1.3" data-path="probability.html"><a href="probability.html#law-of-sample-spaces"><i class="fa fa-check"></i><b>6.1.3</b> Law of Sample Spaces</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="probability.html"><a href="probability.html#combinatorics"><i class="fa fa-check"></i><b>6.2</b> Combinatorics</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability.html"><a href="probability.html#basic-principle-of-counting"><i class="fa fa-check"></i><b>6.2.1</b> Basic Principle of Counting</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability.html"><a href="probability.html#permutations"><i class="fa fa-check"></i><b>6.2.2</b> Permutations</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability.html"><a href="probability.html#combinations"><i class="fa fa-check"></i><b>6.2.3</b> Combinations</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability.html"><a href="probability.html#axioms-of-probability"><i class="fa fa-check"></i><b>6.3</b> Axioms of Probability</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="probability.html"><a href="probability.html#beyond-the-law-of-sample-spaces"><i class="fa fa-check"></i><b>6.3.1</b> Beyond the Law of Sample Spaces</a></li>
<li class="chapter" data-level="6.3.2" data-path="probability.html"><a href="probability.html#set-theory"><i class="fa fa-check"></i><b>6.3.2</b> Set Theory</a></li>
<li class="chapter" data-level="6.3.3" data-path="probability.html"><a href="probability.html#the-axioms-of-probability"><i class="fa fa-check"></i><b>6.3.3</b> The Axioms of Probability</a></li>
<li class="chapter" data-level="6.3.4" data-path="probability.html"><a href="probability.html#the-or-rule"><i class="fa fa-check"></i><b>6.3.4</b> The OR Rule</a></li>
<li class="chapter" data-level="6.3.5" data-path="probability.html"><a href="probability.html#the-and-rule"><i class="fa fa-check"></i><b>6.3.5</b> The AND Rule</a></li>
<li class="chapter" data-level="6.3.6" data-path="probability.html"><a href="probability.html#the-complement-rule"><i class="fa fa-check"></i><b>6.3.6</b> The Complement Rule</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="probability.html"><a href="probability.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>6.4</b> Conditional Probability and Independence</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="probability.html"><a href="probability.html#introduction-1"><i class="fa fa-check"></i><b>6.4.1</b> Introduction</a></li>
<li class="chapter" data-level="6.4.2" data-path="probability.html"><a href="probability.html#mathematical-definition"><i class="fa fa-check"></i><b>6.4.2</b> Mathematical Definition</a></li>
<li class="chapter" data-level="6.4.3" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>6.4.3</b> Independence</a></li>
<li class="chapter" data-level="6.4.4" data-path="probability.html"><a href="probability.html#multiplicative-rule"><i class="fa fa-check"></i><b>6.4.4</b> Multiplicative Rule</a></li>
<li class="chapter" data-level="6.4.5" data-path="probability.html"><a href="probability.html#law-of-total-probability"><i class="fa fa-check"></i><b>6.4.5</b> Law of Total Probability</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="probability.html"><a href="probability.html#bayes-rule"><i class="fa fa-check"></i><b>6.5</b> Bayes Rule</a></li>
<li class="chapter" data-level="6.6" data-path="probability.html"><a href="probability.html#homework-4"><i class="fa fa-check"></i><b>6.6</b> Homework</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="probability.html"><a href="probability.html#concept-questions-4"><i class="fa fa-check"></i><b>6.6.1</b> Concept Questions</a></li>
<li class="chapter" data-level="6.6.2" data-path="probability.html"><a href="probability.html#practice-problems-4"><i class="fa fa-check"></i><b>6.6.2</b> Practice Problems</a></li>
<li class="chapter" data-level="6.6.3" data-path="probability.html"><a href="probability.html#advanced-problems-4"><i class="fa fa-check"></i><b>6.6.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>7</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#random-variables"><i class="fa fa-check"></i><b>7.1</b> Random Variables</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distributions-for-discrete-random-variables"><i class="fa fa-check"></i><b>7.2</b> Probability Distributions for Discrete Random Variables</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#properties-of-probability-distributions"><i class="fa fa-check"></i><b>7.3</b> Properties of Probability Distributions</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expected-values-of-discrete-random-variables"><i class="fa fa-check"></i><b>7.3.1</b> Expected Values of Discrete Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expected-value-of-sums-of-random-variables"><i class="fa fa-check"></i><b>7.4</b> Expected Value of Sums of Random Variables</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance-of-random-variables"><i class="fa fa-check"></i><b>7.5</b> Variance of Random Variables</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance-of-sums-of-random-variables"><i class="fa fa-check"></i><b>7.5.1</b> Variance of Sums of Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#bernoulli-random-variables"><i class="fa fa-check"></i><b>7.6</b> Bernoulli Random Variables</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#binomial-random-variables"><i class="fa fa-check"></i><b>7.7</b> Binomial Random Variables</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#binomial-random-variable-in-r"><i class="fa fa-check"></i><b>7.8</b> Binomial Random Variable in R</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution-in-r"><i class="fa fa-check"></i><b>7.8.1</b> Probability Distribution in R</a></li>
<li class="chapter" data-level="7.8.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#cumulative-distribution-calculations-in-r"><i class="fa fa-check"></i><b>7.8.2</b> Cumulative Distribution Calculations in R</a></li>
<li class="chapter" data-level="7.8.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#random-binomial-distribution-in-r"><i class="fa fa-check"></i><b>7.8.3</b> Random Binomial Distribution in R</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#homework-5"><i class="fa fa-check"></i><b>7.9</b> Homework</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#concept-questions-5"><i class="fa fa-check"></i><b>7.9.1</b> Concept Questions:</a></li>
<li class="chapter" data-level="7.9.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#advanced-problems-5"><i class="fa fa-check"></i><b>7.9.2</b> Advanced Problems:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html"><i class="fa fa-check"></i><b>8</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="8.1" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#introduction-to-continuous-random-variables"><i class="fa fa-check"></i><b>8.1</b> Introduction to Continuous Random Variables</a></li>
<li class="chapter" data-level="8.2" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#uniform-random-variable"><i class="fa fa-check"></i><b>8.2</b> Uniform Random Variable</a></li>
<li class="chapter" data-level="8.3" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#normal-distribution"><i class="fa fa-check"></i><b>8.3</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#cumulative-distribution-function-cdf-for-normal-random-variables"><i class="fa fa-check"></i><b>8.3.1</b> Cumulative Distribution Function (CDF) for Normal Random Variables</a></li>
<li class="chapter" data-level="8.3.2" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#finding-probabilities-for-the-normal-distribution"><i class="fa fa-check"></i><b>8.3.2</b> Finding Probabilities for the Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#standard-normal-distribution-z"><i class="fa fa-check"></i><b>8.4</b> Standard Normal Distribution (<span class="math inline">\(Z\)</span>)</a></li>
<li class="chapter" data-level="8.5" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#assessing-normality"><i class="fa fa-check"></i><b>8.5</b> Assessing Normality</a></li>
<li class="chapter" data-level="8.6" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#regression-to-the-mean"><i class="fa fa-check"></i><b>8.6</b> Regression to the Mean</a></li>
<li class="chapter" data-level="8.7" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#final-thoughts-on-random-variables"><i class="fa fa-check"></i><b>8.7</b> Final Thoughts on Random Variables</a></li>
<li class="chapter" data-level="8.8" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#homework-6"><i class="fa fa-check"></i><b>8.8</b> Homework</a></li>
</ul></li>
<li class="part"><span><b>III Sampling and Confidence Intervals</b></span></li>
<li class="chapter" data-level="9" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html"><i class="fa fa-check"></i><b>9</b> Introduction to Sampling Distributions</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#why-sample"><i class="fa fa-check"></i><b>9.1</b> Why Sample?</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#average-height-example"><i class="fa fa-check"></i><b>9.1.1</b> Average Height Example</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#inferences-and-point-estimators"><i class="fa fa-check"></i><b>9.2</b> Inferences and Point Estimators</a></li>
<li class="chapter" data-level="9.3" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#the-distribution-of-sample-means"><i class="fa fa-check"></i><b>9.3</b> The Distribution of Sample Means</a></li>
<li class="chapter" data-level="9.4" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#distribution-of-sample-means"><i class="fa fa-check"></i><b>9.4</b> Distribution of Sample Means</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>9.4.1</b> The Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#other-point-estimators"><i class="fa fa-check"></i><b>9.5</b> Other Point Estimators</a></li>
<li class="chapter" data-level="9.6" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#sampling-distribution-for-the-sample-proportion"><i class="fa fa-check"></i><b>9.6</b> Sampling Distribution for the Sample Proportion</a></li>
<li class="chapter" data-level="9.7" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#tales-in-sampling-poincares-baker"><i class="fa fa-check"></i><b>9.7</b> Tales in Sampling: Poincare’s Baker</a></li>
<li class="chapter" data-level="9.8" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#homework-7"><i class="fa fa-check"></i><b>9.8</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>10</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="10.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#introduction-nyc-flights-dataset"><i class="fa fa-check"></i><b>10.1</b> Introduction NYC Flights Dataset</a></li>
<li class="chapter" data-level="10.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#mean-flight-delays"><i class="fa fa-check"></i><b>10.2</b> Mean Flight Delays</a></li>
<li class="chapter" data-level="10.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#shortcut-using-the-central-limit-theorem"><i class="fa fa-check"></i><b>10.3</b> Shortcut Using the Central Limit Theorem</a></li>
<li class="chapter" data-level="10.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#additional-practice-comparing-airports"><i class="fa fa-check"></i><b>10.4</b> Additional Practice: Comparing Airports</a></li>
<li class="chapter" data-level="10.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#population-proportion-confidence-intervals"><i class="fa fa-check"></i><b>10.5</b> Population Proportion Confidence Intervals</a></li>
<li class="chapter" data-level="10.6" data-path="confidence-intervals.html"><a href="confidence-intervals.html#extra-practice-problems"><i class="fa fa-check"></i><b>10.6</b> Extra Practice Problems</a></li>
<li class="chapter" data-level="10.7" data-path="confidence-intervals.html"><a href="confidence-intervals.html#homework-8"><i class="fa fa-check"></i><b>10.7</b> Homework</a></li>
</ul></li>
<li class="part"><span><b>IV Regression</b></span></li>
<li class="chapter" data-level="11" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Introduction to Linear Regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#statistical-models"><i class="fa fa-check"></i><b>11.1</b> Statistical Models</a></li>
<li class="chapter" data-level="11.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#fitting-a-linear-model-in-r"><i class="fa fa-check"></i><b>11.2</b> Fitting a Linear Model in R</a></li>
<li class="chapter" data-level="11.3" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#assumptions-of-linear-regression"><i class="fa fa-check"></i><b>11.3</b> Assumptions of Linear Regression</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#successful-linear-regression"><i class="fa fa-check"></i><b>11.3.1</b> Successful Linear Regression</a></li>
<li class="chapter" data-level="11.3.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#what-failure-looks-like"><i class="fa fa-check"></i><b>11.3.2</b> What Failure Looks Like</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>11.4</b> Goodness of Fit</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#correlation-and-slope"><i class="fa fa-check"></i><b>11.4.1</b> Correlation and Slope</a></li>
<li class="chapter" data-level="11.4.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#r2-coefficient-of-determination-and-measuring-model-fits"><i class="fa fa-check"></i><b>11.4.2</b> <span class="math inline">\(R^2\)</span> Coefficient of Determination and Measuring Model Fits</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#using-regression-models-to-make-predictions"><i class="fa fa-check"></i><b>11.5</b> Using Regression Models to Make Predictions</a></li>
<li class="chapter" data-level="11.6" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#homework-9"><i class="fa fa-check"></i><b>11.6</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html"><i class="fa fa-check"></i><b>12</b> Regression with Categorical Variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#introduction-2"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#one-hot-encoding"><i class="fa fa-check"></i><b>12.2</b> One Hot Encoding</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#example-exercise-and-weight"><i class="fa fa-check"></i><b>12.2.1</b> Example: Exercise and Weight</a></li>
<li class="chapter" data-level="12.2.2" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#housing-prices-by-neighborhood"><i class="fa fa-check"></i><b>12.2.2</b> Housing Prices by Neighborhood</a></li>
<li class="chapter" data-level="12.2.3" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#advanced-exercise-and-gender-together"><i class="fa fa-check"></i><b>12.2.3</b> Advanced: Exercise and Gender Together</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#diagnostics"><i class="fa fa-check"></i><b>12.3</b> Diagnostics</a></li>
<li class="chapter" data-level="12.4" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#homework-10"><i class="fa fa-check"></i><b>12.4</b> Homework</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#concept-questions-9"><i class="fa fa-check"></i><b>12.4.1</b> Concept Questions</a></li>
<li class="chapter" data-level="12.4.2" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#practice-problems-10"><i class="fa fa-check"></i><b>12.4.2</b> Practice Problems</a></li>
<li class="chapter" data-level="12.4.3" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#advanced-problems-10"><i class="fa fa-check"></i><b>12.4.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html"><i class="fa fa-check"></i><b>13</b> Multiple Regression Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#introduction-to-multiple-regression-models"><i class="fa fa-check"></i><b>13.1</b> Introduction to Multiple Regression Models</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#housing-prices-review-of-simple-regression-results"><i class="fa fa-check"></i><b>13.1.1</b> Housing Prices (Review of Simple Regression Results)</a></li>
<li class="chapter" data-level="13.1.2" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#multiple-regression-including-bathrooms"><i class="fa fa-check"></i><b>13.1.2</b> Multiple Regression (Including Bathrooms)</a></li>
<li class="chapter" data-level="13.1.3" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#diagnostics-for-multiple-linear-regression"><i class="fa fa-check"></i><b>13.1.3</b> Diagnostics for Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#multiple-regression-with-categorical-variables-including-the-neighborhood"><i class="fa fa-check"></i><b>13.2</b> Multiple Regression with Categorical Variables: Including the Neighborhood</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#predictions"><i class="fa fa-check"></i><b>13.2.1</b> Predictions</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#interactions-between-variables"><i class="fa fa-check"></i><b>13.3</b> Interactions between Variables</a></li>
<li class="chapter" data-level="13.4" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#some-pitfalls-in-multiple-regression"><i class="fa fa-check"></i><b>13.4</b> Some Pitfalls in Multiple Regression</a></li>
<li class="chapter" data-level="13.5" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#homework-11"><i class="fa fa-check"></i><b>13.5</b> Homework</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#concept-questions-10"><i class="fa fa-check"></i><b>13.5.1</b> Concept Questions</a></li>
<li class="chapter" data-level="13.5.2" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#practice-problems-11"><i class="fa fa-check"></i><b>13.5.2</b> Practice Problems</a></li>
<li class="chapter" data-level="13.5.3" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#advanced-problems-11"><i class="fa fa-check"></i><b>13.5.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Hypothesis Testing</b></span></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing: One Sample</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#introduction-and-warning"><i class="fa fa-check"></i><b>14.1</b> Introduction and Warning</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#a-starting-example"><i class="fa fa-check"></i><b>14.2</b> A Starting Example</a></li>
<li class="chapter" data-level="14.3" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#the-t.test-command-hypothesis-tests-for-the-population-mean-mu"><i class="fa fa-check"></i><b>14.3</b> The t.test command: Hypothesis Tests for the Population Mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="14.4" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#theory-of-hypothesis-testing"><i class="fa fa-check"></i><b>14.4</b> Theory of Hypothesis Testing</a></li>
<li class="chapter" data-level="14.5" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#under-the-hood-t-tests"><i class="fa fa-check"></i><b>14.5</b> Under the Hood (t tests)</a></li>
<li class="chapter" data-level="14.6" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>14.6</b> Errors in Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#statistical-significance-alpha"><i class="fa fa-check"></i><b>14.6.1</b> Statistical Significance (<span class="math inline">\(\alpha\)</span>)</a></li>
<li class="chapter" data-level="14.6.2" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#type-ii-error"><i class="fa fa-check"></i><b>14.6.2</b> Type II Error</a></li>
<li class="chapter" data-level="14.6.3" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#practical-significance-versus-statistical-significance"><i class="fa fa-check"></i><b>14.6.3</b> Practical Significance versus Statistical Significance</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#hypothesis-testing-for-population-fraction"><i class="fa fa-check"></i><b>14.7</b> Hypothesis Testing for Population Fraction</a>
<ul>
<li class="chapter" data-level="14.7.1" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#example-3"><i class="fa fa-check"></i><b>14.7.1</b> Example:</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#hypothesis-testing-in-linear-regression"><i class="fa fa-check"></i><b>14.8</b> Hypothesis Testing in Linear Regression</a></li>
<li class="chapter" data-level="14.9" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#power-of-a-statistical-test"><i class="fa fa-check"></i><b>14.9</b> Power of a Statistical Test</a></li>
<li class="chapter" data-level="14.10" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#homework-12"><i class="fa fa-check"></i><b>14.10</b> Homework</a>
<ul>
<li class="chapter" data-level="14.10.1" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#concept-questions-11"><i class="fa fa-check"></i><b>14.10.1</b> Concept Questions:</a></li>
<li class="chapter" data-level="14.10.2" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#practice-problems-12"><i class="fa fa-check"></i><b>14.10.2</b> Practice Problems:</a></li>
<li class="chapter" data-level="14.10.3" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#advanced-problems-12"><i class="fa fa-check"></i><b>14.10.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html"><i class="fa fa-check"></i><b>15</b> Hypothesis Testing: Two Sample Tests</a>
<ul>
<li class="chapter" data-level="15.1" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#two-sample-t-test"><i class="fa fa-check"></i><b>15.1</b> Two Sample t test</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#regression-analysis"><i class="fa fa-check"></i><b>15.1.1</b> Regression analysis</a></li>
<li class="chapter" data-level="15.1.2" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#two-sample-t-test-approach"><i class="fa fa-check"></i><b>15.1.2</b> Two Sample t test approach</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#two-sample-proportion-tests"><i class="fa fa-check"></i><b>15.2</b> Two Sample Proportion Tests</a></li>
<li class="chapter" data-level="15.3" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#extra-example-birth-weights-and-smoking"><i class="fa fa-check"></i><b>15.3</b> Extra Example: Birth Weights and Smoking</a></li>
<li class="chapter" data-level="15.4" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#homework-13"><i class="fa fa-check"></i><b>15.4</b> Homework</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#concept-questions-12"><i class="fa fa-check"></i><b>15.4.1</b> Concept Questions</a></li>
<li class="chapter" data-level="15.4.2" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#practice-problems-13"><i class="fa fa-check"></i><b>15.4.2</b> Practice Problems</a></li>
<li class="chapter" data-level="15.4.3" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#advanced-problems-13"><i class="fa fa-check"></i><b>15.4.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="confidence-intervals-and-hypothesis-testing.html"><a href="confidence-intervals-and-hypothesis-testing.html"><i class="fa fa-check"></i><b>16</b> Confidence Intervals and Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="16.1" data-path="confidence-intervals-and-hypothesis-testing.html"><a href="confidence-intervals-and-hypothesis-testing.html#relation-to-confidence-intervals"><i class="fa fa-check"></i><b>16.1</b> Relation to Confidence Intervals</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="confidence-intervals-and-hypothesis-testing.html"><a href="confidence-intervals-and-hypothesis-testing.html#two-sided-tests"><i class="fa fa-check"></i><b>16.1.1</b> Two sided tests</a></li>
<li class="chapter" data-level="16.1.2" data-path="confidence-intervals-and-hypothesis-testing.html"><a href="confidence-intervals-and-hypothesis-testing.html#one-sided-confidence-intervals"><i class="fa fa-check"></i><b>16.1.2</b> One-sided confidence intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html"><i class="fa fa-check"></i><b>17</b> Introduction to the Chi Square Test</a>
<ul>
<li class="chapter" data-level="17.1" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#contingency-tables"><i class="fa fa-check"></i><b>17.1</b> Contingency Tables</a></li>
<li class="chapter" data-level="17.2" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#chi-square-test"><i class="fa fa-check"></i><b>17.2</b> Chi Square Test</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#conditions-for-using-the-chi2-test"><i class="fa fa-check"></i><b>17.2.1</b> Conditions for Using the <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="17.2.2" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#multiple-hypothesis-testing-again"><i class="fa fa-check"></i><b>17.2.2</b> Multiple Hypothesis Testing Again</a></li>
<li class="chapter" data-level="17.2.3" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#using-a-different-null-hypothesis"><i class="fa fa-check"></i><b>17.2.3</b> Using a different Null Hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#homework-14"><i class="fa fa-check"></i><b>17.3</b> Homework</a></li>
</ul></li>
<li class="part"><span><b>VI Advanced Regression Topics</b></span></li>
<li class="chapter" data-level="18" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>18</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="18.1" data-path="logistic-regression.html"><a href="logistic-regression.html#what-is-logistic-regression-used-for"><i class="fa fa-check"></i><b>18.1</b> What is logistic regression used for?</a></li>
<li class="chapter" data-level="18.2" data-path="logistic-regression.html"><a href="logistic-regression.html#glm-generalized-linear-models"><i class="fa fa-check"></i><b>18.2</b> GLM: Generalized Linear Models</a></li>
<li class="chapter" data-level="18.3" data-path="logistic-regression.html"><a href="logistic-regression.html#a-starting-example-1"><i class="fa fa-check"></i><b>18.3</b> A Starting Example</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#confidence-intervals-for-the-parameters"><i class="fa fa-check"></i><b>18.3.1</b> Confidence Intervals for the Parameters</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="logistic-regression.html"><a href="logistic-regression.html#equivalence-of-logistic-regression-and-proportion-tests"><i class="fa fa-check"></i><b>18.4</b> Equivalence of Logistic Regression and Proportion Tests</a></li>
<li class="chapter" data-level="18.5" data-path="logistic-regression.html"><a href="logistic-regression.html#example-building-a-more-accurate-model"><i class="fa fa-check"></i><b>18.5</b> Example: Building a More Accurate Model</a></li>
<li class="chapter" data-level="18.6" data-path="logistic-regression.html"><a href="logistic-regression.html#example-measuring-team-defense-using-logistic-regression"><i class="fa fa-check"></i><b>18.6</b> Example: Measuring Team Defense Using Logistic Regression</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistics and Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-sampling-distributions" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Chapter 9</span> Introduction to Sampling Distributions<a href="introduction-to-sampling-distributions.html#introduction-to-sampling-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="why-sample" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Why Sample?<a href="introduction-to-sampling-distributions.html#why-sample" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have learned about the properties of probability distributions such as the Normal Distribution. Up until now we assumed we are given a probability distribution and learned how we can extract information from knowledge of the distribution. For example, given that a process follows a binomial distribution how can we calculate the mean? This is probability theory.</p>
<p>Now we are going to start learning <em>Statistics</em> where we are concerned with estimation of parameters from <strong>random samples</strong>.</p>
<p>Example: Lets say we want to estimate the mean height of Schreiner students. Heights follow some distribution function, so one way to do this would be to collect the heights of every Schreiner students and take the average of this list to get an answer. This approach has the advantage of giving an exact answer. However, collecting all that information would be a huge investment of time.</p>
<p>For the Schreiner heights example it would be a hassle to collect all the data. In other situations it may be practically impossible to collect all that information. Imagine a medical study where instead of asking someone how tall they are you have to pay them <span class="math inline">\(30,000\)</span> dollars to participate in a drug trial. No way the drug company is going to pay everyone in the United States to take a drug, or even everyone at Schreiner.</p>
<p>Collecting information is both expensive and time-consuming so we need a better approach.</p>
<div id="average-height-example" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> Average Height Example<a href="introduction-to-sampling-distributions.html#average-height-example" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To illustrate the idea behind sampling lets imagine we did ask every student their height. To simulate this process I create a list of random height values which is 1200 students long. We can then find the average value of the list to get an exact answer for the average height of Schreiner students.</p>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="introduction-to-sampling-distributions.html#cb325-1" aria-hidden="true" tabindex="-1"></a>heights <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1200</span>, <span class="at">mean =</span> <span class="fl">5.5</span>, <span class="at">sd =</span> <span class="dv">4</span><span class="sc">/</span><span class="dv">12</span>)</span>
<span id="cb325-2"><a href="introduction-to-sampling-distributions.html#cb325-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(heights)</span></code></pre></div>
<pre><code>## [1] 5.491722</code></pre>
<p>Thus we find that average height of Schreiner students is exactly 5.4917215 feet. We can also make a histogram our our fake height data for Schreiner students.</p>
<div class="sourceCode" id="cb327"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb327-1"><a href="introduction-to-sampling-distributions.html#cb327-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(heights, <span class="at">col =</span> <span class="st">&quot;coral&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Heights of Schreiner Students&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Proportion of Students&quot;</span>,</span>
<span id="cb327-2"><a href="introduction-to-sampling-distributions.html#cb327-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;Height (ft)&quot;</span>, <span class="at">freq =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-320-1.png" width="672" /></p>
<p>But lets say that I also gave the task of finding the average height to a lazy person (not an Applied Stats student, but maybe after this lesson). They start going around to ask everybody their heights, but get bored and quit after only asking <span class="math inline">\(N\)</span> number of people. When it comes time to report the answer they panic and just average up the people they did ask and turn that in.</p>
<p>How wrong would they be? We can examine this using the <code>sample()</code> command in <code>R</code>. The below command simulates us randomly choosing <span class="math inline">\(N\)</span> people, recording their heights, and then averaging.</p>
<div class="sourceCode" id="cb328"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb328-1"><a href="introduction-to-sampling-distributions.html#cb328-1" aria-hidden="true" tabindex="-1"></a>N<span class="ot">=</span><span class="dv">50</span>; <span class="do">##The number of people they ask before quitting</span></span>
<span id="cb328-2"><a href="introduction-to-sampling-distributions.html#cb328-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">sample</span>(heights, <span class="at">replace=</span><span class="cn">FALSE</span>, <span class="at">size=</span>N)) <span class="do">##the panic answer</span></span></code></pre></div>
<pre><code>## [1] 5.48426</code></pre>
<p>A <strong>very important point</strong> is that if we did this again we would get a slightly different answer this time:</p>
<div class="sourceCode" id="cb330"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb330-1"><a href="introduction-to-sampling-distributions.html#cb330-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">sample</span>(heights, <span class="at">replace =</span> <span class="cn">FALSE</span>, <span class="at">size =</span> N))</span></code></pre></div>
<pre><code>## [1] 5.536182</code></pre>
<p>The answer we get if we quit early will depend on who exactly we asked. For example, if we happened to run into the basketball team and recorded their heights and then quit we would end up with a very <strong>wrong</strong> answer for the mean height of a Schreiner student! However, notice that if we choose only <span class="math inline">\(50\)</span> students at random above we get an answer which is pretty close to the exact answer 5.4917215 we would find if we went to the trouble of asking <strong>every single student on campus their height</strong>.</p>
<div id="analysis" class="section level4 hasAnchor" number="9.1.1.1">
<h4><span class="header-section-number">9.1.1.1</span> Analysis<a href="introduction-to-sampling-distributions.html#analysis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Wow that is not so bad! Unless they are very unlucky they can give a pretty good answer after only doing a fraction of the work. Note however that every time we run the lazy person sample it changes a little bit. This has to do with the order that they ask people in. If they just so happen to ask a few tall people first and then quit the answer can be farther off. However, if they keep asking people this bad luck will be balanced out fairly quickly.</p>
</div>
<div id="why-does-this-work" class="section level4 hasAnchor" number="9.1.1.2">
<h4><span class="header-section-number">9.1.1.2</span> Why does this work?<a href="introduction-to-sampling-distributions.html#why-does-this-work" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>First, notice that their is something magical about the mean. Lets say I have asked 100 students and have an estimate of 5.4 feet for the average height. If we let <span class="math inline">\(h_1, h_2,...h_{100}\)</span> be the heights then we can write this as:
<span class="math display">\[s_{100}=\frac{h_1+h_2+...+h_{100}}{100}=5.40\]</span></p>
<p>I decide to quit, but as I am walking back to my dorm I pass one more person and decide to collect their height as well. It just so happens to be Kevin Durant (a professional basketball player) who is 7 feet tall. If I include him in my sample how does that effect it?</p>
<p><span class="math display">\[s_{101}=\frac{h_1+h_2+...+h_{100}+7.0}{101}=\frac{100}{101}\left(\frac{h_1+h_2+...+h_{100}}{100}+\frac{7.0}{100}\right)=0.990(s_{100}+0.07)=5.4158\]</span></p>
<p>So adding a 7 foot person to your sample only changes it by less than <span class="math inline">\(0.02\)</span> feet. This is because we divided the 7.0 number by the number of samples. It is hard to change the average value after the sample size is large enough. It is resistant to random effects when the sample size is large.</p>
<p>Note, this is our friend the Law of Large Numbers again. Since we are looking for the expected value (average) of the sample we expect this value to become more predictable as we increase the number of people included in the sample.</p>
</div>
</div>
</div>
<div id="inferences-and-point-estimators" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Inferences and Point Estimators<a href="introduction-to-sampling-distributions.html#inferences-and-point-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have seen that it is possible to make some <strong>inference</strong> about the average height of Schreiner students from a <em>sample</em> taken from the whole student body. We expect this value to be vary slightly with the sample we take.</p>
<p>In more general terms we are trying to make an <strong>inference</strong> about the mean of the <em>population distribution</em>. We call the true probability distribution the <em>population distribution</em>. The population distribution for the heights example was shown in our first histogram where we asked every student their height:</p>
<div class="sourceCode" id="cb332"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb332-1"><a href="introduction-to-sampling-distributions.html#cb332-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(heights, <span class="at">col =</span> <span class="st">&quot;coral&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Heights of Schreiner Students&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Proportion of Students&quot;</span>,</span>
<span id="cb332-2"><a href="introduction-to-sampling-distributions.html#cb332-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;Height (ft)&quot;</span>, <span class="at">freq =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-323-1.png" width="672" />
As noted the population distribution is often unobtainable in a practical sense but as the height example shows we may be able to get an idea of its properties by sampling from it. We hope to <em>infer</em> properties of the whole population from a relatively small sample. The process we are engaged in is called <strong>statistical inference</strong>.</p>
<p>In many practical cases we may be interested in estimating some descriptive statistic, instead of the entire population distribution function. For example, we have seen an example where we were looking for an estimate of the mean of the height distribution. We didn’t have to turn in all our height measurements, just the average of them, if you had to turn-in the whole list it would be more obvious who had been lazy and only asked a few people.</p>
<p>When we are only interested in a single number (mean, variance, median, etc) then we are talking about a <strong>point estimator</strong> <span class="math inline">\(\hat{\theta}\)</span>. If we had been looking for the median height of Schreiner students we might have used the median of our sample to estimate the population median. It is vital to understand that a point estimator <span class="math inline">\(\hat{\theta}\)</span> is a random variable, because each time we collect a sample we will get a slightly different answer. The population parameter we are trying to estimate <span class="math inline">\(\theta\)</span> is <strong>NOT</strong> a random variable, but a fixed value we are trying to estimate. There is an average height of Schreiner student!</p>
<p>Since <span class="math inline">\(\hat{\theta}\)</span> is a random variable we can use probability theory to analyze its properties.</p>
</div>
<div id="the-distribution-of-sample-means" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> The Distribution of Sample Means<a href="introduction-to-sampling-distributions.html#the-distribution-of-sample-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We are now ready to use probability theory to analyze the properties of the point estimator <span class="math inline">\(\hat{\theta}\)</span> random variables. We will focus on a the special point estimator <span class="math inline">\(\bar{X}\)</span> which uses the <strong>sample mean</strong> to form an estimate for the population mean. The random sample and then average procedure we have been using can be written in terms of random variables.
<span class="math display">\[\bar{X}=\frac{1}{N} \sum_{j=1}^N X_j.\]</span> Here <span class="math inline">\(\bar{X}\)</span> is the random variable describing the outcomes from sampling <span class="math inline">\(N\)</span> values from a population which follows the random variable <span class="math inline">\(X_j\)</span>. Each of the random variables <span class="math inline">\(X_j\)</span> are independent and identically distributed. For the heights of Schreiner students example, each <span class="math inline">\(X_j\)</span> is the height of a randomly chosen student.</p>
<p>Since <span class="math inline">\(\bar{X}\)</span> is defined as the <em>sum</em> of random variables we can use our property of expected values <span class="math inline">\(E[aX+bY]=aE[X]+E[Y]\)</span> to find the expected value of the random variable <span class="math inline">\(\bar{X}\)</span>. In particular we have that,
<span class="math display">\[E[\bar{X}]=E\left[\frac{1}{N} \sum_{j=1}^N X_j \right]=\frac{1}{N}\sum_{j=1}^N E[X_j]=\frac{N \mu}{N}=\mu.\]</span>
Where <span class="math inline">\(\mu\)</span> is the population mean. If the expected value of the point estimator <span class="math inline">\(\hat{\theta}\)</span> equals the population parameter it is trying to estimate <span class="math inline">\(E[\hat{\theta}]=\theta\)</span> we say that the estimator is an <strong>unbiased</strong> estimator for <span class="math inline">\(\theta\)</span>. In turn if an estimator does not have this property we say that the estimator is <strong>biased</strong>.</p>
<p>Another important property of a statistical estimator is the variance of the sampling distribution. This measures how variable the answers will be depending on the random sample we take from the population distribution. For the sample mean estimator <span class="math inline">\(\bar{X}\)</span> we can find the variance of our random sample using the properties <span class="math inline">\(Var(aX+bY)=a^2 Var(X)+b^2Var(Y)\)</span> for independent random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.
<span class="math display">\[\begin{align}
&amp;Var(\bar{X})=\sigma^2_{\bar{X}}=Var\left[\frac{1}{N} \sum_{j=1}^N X_j \right]=\frac{1}{N^2}\sum_{j=1}^N Var[X_j]=\frac{N \sigma^2}{N^2}=\frac{\sigma^2}{N} \\
&amp; \sigma_{\bar{X}}=\frac{\sigma}{\sqrt{N}}
\end{align}\]</span>
The standard deviation of the point estimator is called the <strong>standard error of the estimator</strong> <span class="math inline">\(\sigma_{\bar{X}}\)</span>. Notice that no matter how large the population standard deviation <span class="math inline">\(\sigma\)</span> is, the standard error of the sample mean estimator goes to zero as the sample size goes to infinity. Therefore, if we take large enough samples the sample mean will become very close to the population mean.</p>
<div class="sourceCode" id="cb333"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb333-1"><a href="introduction-to-sampling-distributions.html#cb333-1" aria-hidden="true" tabindex="-1"></a>sample.size <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb333-2"><a href="introduction-to-sampling-distributions.html#cb333-2" aria-hidden="true" tabindex="-1"></a>store <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">10000</span>, <span class="fu">mean</span>(<span class="fu">sample</span>(heights, <span class="at">size =</span> sample.size, <span class="at">replace =</span> <span class="cn">TRUE</span>)))</span>
<span id="cb333-3"><a href="introduction-to-sampling-distributions.html#cb333-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(store, <span class="at">col =</span> <span class="st">&quot;coral&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Sample mean&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Distribution of Sample Means N=50&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-324-1.png" width="672" /></p>
<p>The standard deviation of this distribution is <span class="math inline">\(\sigma_{\bar{X}}=\)</span><code>0.0468746</code> found through simulation above. If we used our formula for the standard error we get <span class="math display">\[\sigma_{\bar{X}}=\frac{\sigma}{\sqrt{N}}=\frac{4/12}{\sqrt{50}}=0.047\]</span></p>
<p>Thus our random sampling will produce a very accurate and consistent answer for the population mean if we only ask 50 out of the roughly 1200 students are Schreiner!</p>
<p>It is very important to remember that our formula for the standard error for the sample mean point estimator <strong>ONLY</strong> applies if we take a truly random sample, where each data point is exactly independent of all the others. If we did our “random” sample by standing outside the gym after basketball practice gets out we will get much,much worse results.</p>
<div class="exercise">
<p><span id="exr:unnamed-chunk-325" class="exercise"><strong>Exercise 9.1  </strong></span>What is the standard error for our height sampling problem if we ask 100 randomly chosen students?</p>
</div>
<div class="exercise">
<p><span id="exr:unnamed-chunk-326" class="exercise"><strong>Exercise 9.2  </strong></span>How many samples should I take if I want to <span class="math inline">\(\sigma_{\bar{X}}&lt;0.01\)</span>, if I am sampling from a population with <span class="math inline">\(\sigma=1\)</span>?</p>
</div>
<div class="exercise">
<p><span id="exr:unnamed-chunk-327" class="exercise"><strong>Exercise 9.3  </strong></span>Do the above results depend on the distribution of the random variables <span class="math inline">\(X_j\)</span>?</p>
</div>
</div>
<div id="distribution-of-sample-means" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> Distribution of Sample Means<a href="introduction-to-sampling-distributions.html#distribution-of-sample-means" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>You may notice that our distribution of sample means above looks suspiciously like a normal distribution. Lets investigate this will our tools for <strong>assessing normality</strong> learned in the last chapter. We have already made a histogram and it looks like a normal distribution to me, so we proceed to step 2:</p>
<div class="sourceCode" id="cb334"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb334-1"><a href="introduction-to-sampling-distributions.html#cb334-1" aria-hidden="true" tabindex="-1"></a><span class="fu">IQR</span>(store)<span class="sc">/</span><span class="fu">sd</span>(store)</span></code></pre></div>
<pre><code>## [1] 1.346072</code></pre>
<p>This is <em>close</em> to the target value of 1.3. To finish we will make a QQ plot of our distribution of sample means:</p>
<div class="sourceCode" id="cb336"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb336-1"><a href="introduction-to-sampling-distributions.html#cb336-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(store)</span>
<span id="cb336-2"><a href="introduction-to-sampling-distributions.html#cb336-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(store, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-329-1.png" width="672" /></p>
<p>This plot shows that the distribution of sample means is very well approximated by a normal distribution. It turns out this will be true whenever the population distribution follows a normal distribution <span class="math inline">\(N(\mu, \sigma)\)</span>, the distribution of sample means will also follow a normal distribution with the same mean <span class="math inline">\(\mu\)</span> and a standard deviation which decreases with the sample size <span class="math inline">\(N(\mu, \sigma/\sqrt{N})\)</span>. We can use this information to calculate the probability of obtaining results in our sampling. For example, the odds that we ask 50 random Schreiner students their heights and our sample mean is less than <code>5.3</code> is given by:</p>
<div class="sourceCode" id="cb337"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb337-1"><a href="introduction-to-sampling-distributions.html#cb337-1" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fu">mean</span>(heights)  <span class="do">##mu the population mean</span></span>
<span id="cb337-2"><a href="introduction-to-sampling-distributions.html#cb337-2" aria-hidden="true" tabindex="-1"></a>my.sd <span class="ot">=</span> <span class="fu">sd</span>(heights)<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">50</span>)  <span class="do">##the standard deviation of sample means, with sample size 50</span></span>
<span id="cb337-3"><a href="introduction-to-sampling-distributions.html#cb337-3" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fl">5.4</span>, <span class="at">mean =</span> m, <span class="at">sd =</span> my.sd)</span></code></pre></div>
<pre><code>## [1] 0.02408209</code></pre>
<div id="the-central-limit-theorem" class="section level3 hasAnchor" number="9.4.1">
<h3><span class="header-section-number">9.4.1</span> The Central Limit Theorem<a href="introduction-to-sampling-distributions.html#the-central-limit-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>What if the population distribution we are sampling from is <strong>NOT</strong> a normal distribution? Can we say anything about the distribution of sample means in that case?</p>
<p>To investigate this lets create a population of heights which is uniform.</p>
<div class="sourceCode" id="cb339"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb339-1"><a href="introduction-to-sampling-distributions.html#cb339-1" aria-hidden="true" tabindex="-1"></a>heights.uniform <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1200</span>, <span class="at">min =</span> <span class="dv">5</span>, <span class="at">max =</span> <span class="dv">6</span>)</span>
<span id="cb339-2"><a href="introduction-to-sampling-distributions.html#cb339-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(heights.uniform, <span class="at">col =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Uniform Population Distribution of Heights&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-331-1.png" width="672" /></p>
<p>Just like before we could simulate asking 50 students their heights and then averaging using the sample command.</p>
<div class="sourceCode" id="cb340"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb340-1"><a href="introduction-to-sampling-distributions.html#cb340-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">sample</span>(heights.uniform, <span class="at">size =</span> <span class="dv">50</span>))</span></code></pre></div>
<pre><code>## [1] 5.471628</code></pre>
<p>Each time we do this we would get a slightly different answer:</p>
<div class="sourceCode" id="cb342"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb342-1"><a href="introduction-to-sampling-distributions.html#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">sample</span>(heights.uniform, <span class="at">size =</span> <span class="dv">50</span>))</span></code></pre></div>
<pre><code>## [1] 5.496113</code></pre>
<p>If we imagine repeating this experiment many times, asking 50 random students their heights and then averaging, we can get an idea of the distribution of sample means.</p>
<div class="sourceCode" id="cb344"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb344-1"><a href="introduction-to-sampling-distributions.html#cb344-1" aria-hidden="true" tabindex="-1"></a>sample.size <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb344-2"><a href="introduction-to-sampling-distributions.html#cb344-2" aria-hidden="true" tabindex="-1"></a>sample.uniform <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">10000</span>, <span class="fu">mean</span>(<span class="fu">sample</span>(heights.uniform, <span class="at">size =</span> sample.size,</span>
<span id="cb344-3"><a href="introduction-to-sampling-distributions.html#cb344-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">replace =</span> <span class="cn">TRUE</span>)))</span>
<span id="cb344-4"><a href="introduction-to-sampling-distributions.html#cb344-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(sample.uniform, <span class="at">col =</span> <span class="st">&quot;coral&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Sample mean&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Distribution of Sample Means for a Uniform Pop Dist N=50&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-334-1.png" width="672" /></p>
<p>Surprisingly this looks a lot like a Normal distribution!. Lets investigate this further:</p>
<div class="sourceCode" id="cb345"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb345-1"><a href="introduction-to-sampling-distributions.html#cb345-1" aria-hidden="true" tabindex="-1"></a><span class="fu">IQR</span>(sample.uniform)<span class="sc">/</span><span class="fu">sd</span>(sample.uniform)</span></code></pre></div>
<pre><code>## [1] 1.355248</code></pre>
<p>This is relatively close to the Normal distribution value of 1.3. So we proceed to make a QQ plot:</p>
<div class="sourceCode" id="cb347"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb347-1"><a href="introduction-to-sampling-distributions.html#cb347-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(sample.uniform)</span>
<span id="cb347-2"><a href="introduction-to-sampling-distributions.html#cb347-2" aria-hidden="true" tabindex="-1"></a><span class="fu">qqline</span>(sample.uniform, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-336-1.png" width="672" /></p>
<p>Thus our sampling distribution is well approximated by a normal distribution. This result is known as the <strong>central limit theorem</strong>.</p>
<div class="theorem">
<p><span id="thm:unnamed-chunk-337" class="theorem"><strong>Theorem 9.1  (Central Limit Theorem) </strong></span>Consider a random sample of <span class="math inline">\(n\)</span> observations selected from a population (<em>any</em> population) with a mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>. Then when <span class="math inline">\(n\)</span> is sufficiently large the sampling distribution of <span class="math inline">\(\bar{x}\)</span> for the sample mean will be <em>approximately normal</em> with mean <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}\)</span>. The larger the sample size the better the normal approximation will become.</p>
</div>
<p><strong>Key Points</strong></p>
<ol style="list-style-type: decimal">
<li>This is the most powerful tool in statistics.</li>
<li>Notice that <em>sufficiently large</em> is purposely vague in the statement. It will vary with how bizarre our population distribution may be. A rule of thumb is that a sample size of <span class="math inline">\(n\geq 30\)</span> is generally enough for the CLT to provide an accurate answer.</li>
<li>The CLT applies only to the sampling distribution of sample means. If we want to estimate the median, variance, IQR, etc of the population we can’t use the CLT.</li>
</ol>

<div class="warning">
Whenever you are considering a statistical result you should ask is the central limit theorem being applied to produce this result? If yes then make sure the conditons have been satisfied.
</div>

<div class="fallacy">
Misuse of the central limit theorem is perhaps the most common abuse of statistics. Usually, it is applied to data with small sample sizes <span class="math inline">\(N&lt;30\)</span>.
</div>
<div class="exercise">
<p><span id="exr:unnamed-chunk-340" class="exercise"><strong>Exercise 9.4  </strong></span>Repeat the above analysis for estimating the mean value of a uniform population, using a sample size of only 10. Does the sample mean distribution pass the evaluations for normality in this case?</p>
</div>
<div class="exercise">
<p><span id="exr:unnamed-chunk-341" class="exercise"><strong>Exercise 9.5  </strong></span>If we randomly sample 36 data points from a population which has a mean <span class="math inline">\(\mu=0\)</span> and a standard deviation of <span class="math inline">\(\sigma=3.0\)</span>. Estimate the probability that we get a sample mean greater than 7, i.e. <span class="math inline">\(\mathbb{P}(\bar{X}&gt;7)\)</span></p>
</div>
</div>
</div>
<div id="other-point-estimators" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> Other Point Estimators<a href="introduction-to-sampling-distributions.html#other-point-estimators" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have focused mainly on the point estimator for the sample mean. This is because we can find a <strong>formula</strong> for the standard error and expected value for that point estimator. Additionally, we have the power of the central limit theorem at our disposal. However, let us not forget that many other interesting point estimators <span class="math inline">\(\hat{\theta}\)</span> exist. For example, if we wanted to estimate the variance of the heights of Schreiner students, we could randomly sample the heights and estimate the population variance using this <strong>sample variance</strong>.</p>
<div class="sourceCode" id="cb348"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb348-1"><a href="introduction-to-sampling-distributions.html#cb348-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(<span class="fu">sample</span>(heights, <span class="at">size =</span> <span class="dv">50</span>))</span></code></pre></div>
<pre><code>## [1] 0.09775346</code></pre>
<p>If we do this again we will get a slightly different answer:</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="introduction-to-sampling-distributions.html#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(<span class="fu">sample</span>(heights, <span class="at">size =</span> <span class="dv">50</span>))</span></code></pre></div>
<pre><code>## [1] 0.1055983</code></pre>
<p>If we do this many times we can get a distribution of sample variances, which we can plot as a histogram:</p>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="introduction-to-sampling-distributions.html#cb352-1" aria-hidden="true" tabindex="-1"></a>sample.size <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb352-2"><a href="introduction-to-sampling-distributions.html#cb352-2" aria-hidden="true" tabindex="-1"></a>store.var <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">10000</span>, <span class="fu">var</span>(<span class="fu">sample</span>(heights, <span class="at">size =</span> sample.size, <span class="at">replace =</span> <span class="cn">TRUE</span>)))</span>
<span id="cb352-3"><a href="introduction-to-sampling-distributions.html#cb352-3" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(store.var, <span class="at">col =</span> <span class="st">&quot;coral&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Sample SD&quot;</span>, <span class="at">main =</span> <span class="st">&quot;Distribution of Sample Variance N=50&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-344-1.png" width="672" /></p>
<p>The mean of this distribution of sample variances is <code>0.1079259</code> which is close to the population variance of <code>0.1077395</code>. The standard error for this point estimator is approximately <code>0.0218739</code>, estimated by finding the standard deviation of the sampling distribution in the above histogram.</p>
<p>For these exercises we will use the applet “SamplingDemo”. If your version of my RPackage has been updated then you can launch this applet with the command:</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="introduction-to-sampling-distributions.html#cb353-1" aria-hidden="true" tabindex="-1"></a><span class="fu">runHannayApp</span>(<span class="st">&quot;SamplingDemo&quot;</span>)</span></code></pre></div>
<p>Answer the following questions using this applet.</p>
<div class="exercise">
<p><span id="exr:unnamed-chunk-346" class="exercise"><strong>Exercise 9.6  </strong></span>Set the population distribution to Normal and sample size to 30. Does the sampling distribution look normally distributed when the point estimator used is the:
+ Mean
+ Median</p>
</div>
<div class="exercise">
<p><span id="exr:unnamed-chunk-347" class="exercise"><strong>Exercise 9.7  </strong></span>Use the mean point estimator with samnple size greater than 30. Does the sampling distribution look normally distributed when the population is uniform, beta, binomial ? What theorem can we use to tell us this?</p>
</div>
<div class="exercise">
<p><span id="exr:unnamed-chunk-348" class="exercise"><strong>Exercise 9.8  </strong></span>What happens to the standard error as the sample size increases for any of these point estimators?</p>
</div>
<div class="exercise">
<p><span id="exr:unnamed-chunk-349" class="exercise"><strong>Exercise 9.9  </strong></span>The dashed red lines in the sampling distribution plot show the 2.5% and 97.5% quantiles of the sampling distribution. How often do we expect that the population parameter (blue line) will fall outside these limits?</p>
</div>
</div>
<div id="sampling-distribution-for-the-sample-proportion" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> Sampling Distribution for the Sample Proportion<a href="introduction-to-sampling-distributions.html#sampling-distribution-for-the-sample-proportion" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>You suspect a coin may be biased and want to estimate the fraction of flips which come up heads by collecting data. That is we want to <strong>infer</strong> the population parameter <span class="math inline">\(p\)</span> from finite samples. You could think of estimating the fraction of heads from the data using the point estimator <span class="math display">\[\hat{p}=\frac{1}{N} \sum_{j=1} X_j\]</span> where each <span class="math inline">\(X_j\)</span> is a Bernoulli trial (comes out 1 if a heads appears, and 0 if a tails appears.) Since <span class="math inline">\(N\)</span> is finite we expect that each time we flipped the coin <span class="math inline">\(N\)</span> times we will get a slightly different answer. Therefore, <span class="math inline">\(\hat{p}\)</span> is a random variable.</p>
<p>We can find the expected value of the <span class="math inline">\(\hat{p}\)</span> point estimator <span class="math display">\[E[\hat{p}]=E\left[\frac{1}{N} \sum_{j=1}^N X_j \right]=\frac{1}{N} \sum_{j=1}^N E[X_j]=\frac{Np}{p}=p\]</span> This tells us that <span class="math inline">\(\hat{p}\)</span> is an unbiased estimator for the population parameter <span class="math inline">\(p\)</span>. The variance of our estimator <span class="math inline">\(\sigma^2_{\hat{p}}\)</span> for our estimator is given by:
<span class="math display">\[\begin{align}
Var\left[\frac{1}{N} \sum_{j=1}^N X_j \right]=\frac{1}{N^2} \sum_{j=1}^N Var[X_j]=\frac{Npq}{N^2}=\frac{pq}{N}
\end{align}\]</span>
using that the variance of a Bernoulli trial is <span class="math inline">\(p(1-p)=pq\)</span>. Therefore, the standard error of a our point estimator <span class="math inline">\(\hat{p}\)</span> is given by:
<span class="math display">\[\sigma_{\hat{p}}=\sqrt{\frac{pq}{N}}=\sqrt{\frac{p(1-p)}{N}}\]</span>
Thus, as expected the standard error decreases with the sample size <span class="math inline">\(N\)</span> considered. In addition, for <strong>large sample sizes</strong> this estimator is approximately normal. A good rule of thumb for using the normal distribution as an approximation is given by:</p>
<p><strong>Rule of Thumb for <span class="math inline">\(\hat{p}\)</span> Normal Approximation: </strong></p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(N\hat{p}\geq 15\)</span></p></li>
<li><p><span class="math inline">\(N(1-\hat{p})\geq15\)</span></p></li>
</ol>
<div id="example" class="section level4 hasAnchor" number="9.6.0.1">
<h4><span class="header-section-number">9.6.0.1</span> Example:<a href="introduction-to-sampling-distributions.html#example" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>To figure out how popular a city proposal is, we conduct a survey of 100 randomly chosen people. If 40 people are in favor of the proposal then estimate the fraction of the whole city which support the proposal. Estimate odds that the true percentage is greater than 50?</li>
</ol>
<p>Our best estimate for the fraction of people of that support the proposal is <span class="math inline">\(\frac{40}{100}=0.40\)</span>, with a standard error of <span class="math inline">\(\sigma_{\hat{p}}=\sqrt{p(1-p)/N}\)</span>, using <code>R</code> to compute this gives:</p>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="introduction-to-sampling-distributions.html#cb354-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(<span class="fl">0.4</span> <span class="sc">*</span> <span class="fl">0.6</span><span class="sc">/</span><span class="dv">100</span>)</span></code></pre></div>
<pre><code>## [1] 0.04898979</code></pre>
<p>You can also use a shortcut function I wrote to compute this standard error:</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="introduction-to-sampling-distributions.html#cb356-1" aria-hidden="true" tabindex="-1"></a><span class="fu">proportion.se</span>(<span class="dv">40</span>, <span class="dv">100</span>)</span></code></pre></div>
<pre><code>## [1] 0.04898979</code></pre>
<p>To find the odds that the true percentage is greater than 50% we can use the normal approximation. This is justified here because <span class="math inline">\(N\hat{p}=100*0.40=40\geq 15\)</span> and <span class="math inline">\(N(1-\hat{p})=100*0.60=60 \geq 15\)</span>. To find these odds we can use <code>pnorm</code> with mean=<span class="math inline">\(\hat{p}\)</span> and standard deviation given by the standard error we found above.</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="introduction-to-sampling-distributions.html#cb358-1" aria-hidden="true" tabindex="-1"></a>se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fl">0.4</span> <span class="sc">*</span> <span class="fl">0.6</span><span class="sc">/</span><span class="dv">100</span>)</span>
<span id="cb358-2"><a href="introduction-to-sampling-distributions.html#cb358-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">0.5</span>, <span class="at">mean =</span> <span class="fl">0.4</span>, <span class="at">sd =</span> se)</span></code></pre></div>
<pre><code>## [1] 0.02061342</code></pre>
<p>So based on our sample the odds that the true percentage of support in the population exceeds 50% is about 2%.</p>
<div class="exercise">
<p><span id="exr:unnamed-chunk-353" class="exercise"><strong>Exercise 9.10  </strong></span>The San Antonio Spurs have won 40 of their first 55 games of the NBA season. We would like to estimate their winning percentage <span class="math inline">\(p\)</span> giving the probability that they will win any given game using this data. Find an interval which should contain the Spurs true winning percentage about 95% of the time (Hint: Use the Normal Approximation and the Empirical Rule)</p>
</div>

<div class="fallacy">
The basis for all statistical reasoning is random sampling. When a sample is not drawn <em>truly</em> randomly the entire statistical procedures that follow are suspect.
</div>
</div>
</div>
<div id="tales-in-sampling-poincares-baker" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> Tales in Sampling: Poincare’s Baker<a href="introduction-to-sampling-distributions.html#tales-in-sampling-poincares-baker" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The french mathematician Jules-Henri Poincare visited the same baker each day to get his daily loaf of bread. He began to suspect that the loaves he was recieving were less than the 1000 grams advertised. To see if this was really the case he began weighing his daily bread loaves and kept a detailed bread journal of the results. The poor baker had no idea that Poincare was keeping a bread journal and just grabbed a loaf randomly each day to give him.</p>
<p>Unfortunately, Poincare’s bread data has been lost to history at this point. However, I have recreated data with the same key components that he found.</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="introduction-to-sampling-distributions.html#cb360-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(poincare_bread)</span>
<span id="cb360-2"><a href="introduction-to-sampling-distributions.html#cb360-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(poincare_bread<span class="sc">$</span>bread.before)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   878.0   934.2   948.3   950.0   965.2  1042.5</code></pre>
<p>After collecting data for one year he found that the average bread loaf he recieved was only 950 grams. He also looked at the distribution of bread weights and observed a roughly normal distribution.</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="introduction-to-sampling-distributions.html#cb362-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(poincare_bread<span class="sc">$</span>bread.before, <span class="at">main =</span> <span class="st">&quot;Poincare Bread Police Part I&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Number of Loaves&quot;</span>,</span>
<span id="cb362-2"><a href="introduction-to-sampling-distributions.html#cb362-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;Weight (g)&quot;</span>, <span class="at">col =</span> <span class="st">&quot;brown&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-356-1.png" width="672" /></p>
<p>Poincare promptly contacted the police and the baker was cited for selling underweight loaves.</p>
<div class="exercise">
<p><span id="exr:unnamed-chunk-357" class="exercise"><strong>Exercise 9.11  </strong></span>How did poincare convince the police that he had convincing evidence that the baker was selling underweight loaves? Hint: Calculate the standard error of his estimation for the mean bread weight. Then use the empirical rule in combo with the central limit theorem.</p>
</div>
<p>Amazingly, the story continues and Poincare continued to get his bread from the same baker and he maintained his weighing and bread journal. However, <em>now the baker knew that Poincare had reported him to the bread police</em>.</p>
<p>Once again Poincare was able to find an anomaly in his bread data. Although the average weight of his loaves was now sufficient when he plotted a histogram of his bread weights since the initial police visit they did not show a mound shaped distribution. In fact, they now had a distinct lean to them. His new bread distribution had a surplus of heavy loaves and a relative sparsity of lighter loaves.</p>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="introduction-to-sampling-distributions.html#cb363-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(poincare_bread<span class="sc">$</span>bread.after, <span class="at">main =</span> <span class="st">&quot;Bread Weights after first Police Visit&quot;</span>,</span>
<span id="cb363-2"><a href="introduction-to-sampling-distributions.html#cb363-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;Number of Loaves&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;Bread Weights&quot;</span>, <span class="at">col =</span> <span class="st">&quot;brown&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-358-1.png" width="672" /></p>
<div class="exercise">
<p><span id="exr:unnamed-chunk-359" class="exercise"><strong>Exercise 9.12  </strong></span>Why did the distribution change? What has the baker been doing? Hint what would you do in the baker’s shoes…</p>
</div>
<p>Poincare reported the baker once again to the bread police. Not sure what happened after this point, but I think we can assume that the baker either (i) quit baking bread (ii) stopped serving Poincare or (iii) corrected his recipes.</p>
</div>
<div id="homework-7" class="section level2 hasAnchor" number="9.8">
<h2><span class="header-section-number">9.8</span> Homework<a href="introduction-to-sampling-distributions.html#homework-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="concept-questions-6" class="section level4 hasAnchor" number="9.8.0.1">
<h4><span class="header-section-number">9.8.0.1</span> Concept Questions:<a href="introduction-to-sampling-distributions.html#concept-questions-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Are the following statements true? If so, then why? If not then why not?</p>
<ol style="list-style-type: decimal">
<li>The standard error for a point estimator <span class="math inline">\(\hat{\theta}\)</span> is given by <span class="math inline">\(\sigma_{\hat{\theta}}=\dfrac{\sigma}{\sqrt{N}}\)</span>.</li>
<li>If <span class="math inline">\(E[\hat{\theta}]=\theta\)</span> then we say the point estimator <span class="math inline">\(\hat{\theta}\)</span> is unbiased.</li>
<li>The distribution of the sample mean point estimator <span class="math inline">\(\bar{X}\)</span> is unbiased and is normally distributed for large enough sample sizes.</li>
<li>To calculate the standard error for the sample mean point estimator <span class="math inline">\(\bar{X}\)</span> we need to know the standard deviation of the population distribution.</li>
<li>The point estimator <span class="math inline">\(\hat{\theta}\)</span> is a random variable which has a normal distribution.</li>
</ol>
</div>
<div id="practice-problems-7" class="section level4 hasAnchor" number="9.8.0.2">
<h4><span class="header-section-number">9.8.0.2</span> Practice Problems:<a href="introduction-to-sampling-distributions.html#practice-problems-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>How many samples are needed to have a standard error of less than <span class="math inline">\(0.1\)</span> for the sample mean <span class="math inline">\(\bar{X}\)</span> estimator if we are sampling from a population with a distribution <span class="math inline">\(\sigma=1.5\)</span>?</li>
<li>If we randomly sample <span class="math inline">\(100\)</span> data points from a population with standard deviation <span class="math inline">\(\sigma=2.0\)</span>. If the sample mean of our data set is <span class="math inline">\(36\)</span> what is the probability that the next sample we take is:
<ul>
<li>Greater than <span class="math inline">\(40\)</span>?</li>
<li>Between <span class="math inline">\(32\)</span> and <span class="math inline">\(40\)</span>?</li>
<li>Greater than <span class="math inline">\(36\)</span>?</li>
</ul></li>
</ol>
</div>
<div id="advanced-problems-7" class="section level4 hasAnchor" number="9.8.0.3">
<h4><span class="header-section-number">9.8.0.3</span> Advanced Problems:<a href="introduction-to-sampling-distributions.html#advanced-problems-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li><strong>Toads</strong>: You are trying to estimate the girth of Kerrville toads. From your many years of experience in the study of toad girths you know that the standard deviation of toad girths is about <span class="math inline">\(\sigma=40\)</span>mm for normal Texas toads. You collect 100 toads from many different ponds, rivers, witches cauldrons, etc around Kerrville. This is in the data set toad_girth, using this data set find the following:
<ul>
<li>What is your estimate for the mean toad girth in Kerrville?</li>
<li>What is the standard error for this estimation?</li>
<li>How many toads would you have to measure if you wanted to estimate the mean girth of Kerrville toads with a standard error of less than 1mm?</li>
</ul></li>
<li><strong>Hogwarts:</strong> The Hogwarts_heights data set (<code>data(Hogwarts_Heights)</code>) gives the heights of all students and magical creatures at Hogwarts. Suppose we would like to estimate the <strong>typical height</strong> of a life-form at Hogwarts data set by sampling.
<ul>
<li>Conduct EDA to determine the best measure of central tendency for this data set. Justify your answer.</li>
<li>Using R estimate the standard error of your point estimator for a sample of 50 data points.</li>
<li>What if we increase the sample to 100 data points?</li>
</ul></li>
<li><strong>Drug Use:</strong>
The below table gives the data from a survey of 20 and 21 year olds and the percentage of them who admitted to drinking alcohol.</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="left">age</th>
<th align="right">n</th>
<th align="right">alcohol_use</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">20</td>
<td align="right">2271</td>
<td align="right">69.7</td>
</tr>
<tr class="even">
<td align="left">21</td>
<td align="right">2354</td>
<td align="right">83.2</td>
</tr>
</tbody>
</table>
<p>The n column gives the size of the survey (number of people asked in each category). Given this information estimate the probability of the following events:</p>
<ul>
<li>The probability if we repeat the survey we will find the percentage of alcohol in 21 year olds exceeds 69.7?</li>
<li>The probability that if we repeat the experiment we will find that the percentage of use in 20 year olds exceeds 68?</li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="continuous-random-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="confidence-intervals.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/08-Intro_to_Sampling.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["statsbook.pdf", "statsbook.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"collapse": "section"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
