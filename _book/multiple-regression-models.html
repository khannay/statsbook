<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Multiple Regression Models | Introduction to Statistics and Data Science</title>
  <meta name="description" content="Introductory textbook for statistics and data science" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Multiple Regression Models | Introduction to Statistics and Data Science" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Introductory textbook for statistics and data science" />
  <meta name="github-repo" content="khannay/statsbook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Multiple Regression Models | Introduction to Statistics and Data Science" />
  
  <meta name="twitter:description" content="Introductory textbook for statistics and data science" />
  

<meta name="author" content="Dr.Â Kevin Hannay" />


<meta name="date" content="2023-02-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression-with-categorical-variables.html"/>
<link rel="next" href="hypothesis-testing-one-sample.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="toc.css" type="text/css" />
<link rel="stylesheet" href="font-awesome.min.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> Stats Notes </a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#librarian-or-farmer"><i class="fa fa-check"></i><b>1.1</b> Librarian or Farmer?</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#profits"><i class="fa fa-check"></i><b>1.2</b> Profits</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#accidental-deaths"><i class="fa fa-check"></i><b>1.3</b> Accidental Deaths</a></li>
</ul></li>
<li class="part"><span><b>I Exploratory Data Analysis</b></span></li>
<li class="chapter" data-level="2" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i><b>2</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#what-is-r"><i class="fa fa-check"></i><b>2.1</b> What is R?</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#r-packages"><i class="fa fa-check"></i><b>2.2</b> R Packages</a></li>
<li class="chapter" data-level="2.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#r-as-a-fancy-calculator"><i class="fa fa-check"></i><b>2.3</b> R as a Fancy Calculator</a></li>
<li class="chapter" data-level="2.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#more-advanced-r"><i class="fa fa-check"></i><b>2.4</b> More Advanced R</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#data-types-in-r"><i class="fa fa-check"></i><b>2.4.1</b> Data Types in R</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-to-r.html"><a href="introduction-to-r.html#logic-in-r"><i class="fa fa-check"></i><b>2.5</b> Logic in R</a></li>
<li class="chapter" data-level="2.6" data-path="introduction-to-r.html"><a href="introduction-to-r.html#storing-data-in-r"><i class="fa fa-check"></i><b>2.6</b> Storing Data in R</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#vectors"><i class="fa fa-check"></i><b>2.6.1</b> Vectors</a></li>
<li class="chapter" data-level="2.6.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#data-frames"><i class="fa fa-check"></i><b>2.6.2</b> Data Frames</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="introduction-to-r.html"><a href="introduction-to-r.html#basic-plots-in-r"><i class="fa fa-check"></i><b>2.7</b> Basic Plots in R</a></li>
<li class="chapter" data-level="2.8" data-path="introduction-to-r.html"><a href="introduction-to-r.html#additional-resources"><i class="fa fa-check"></i><b>2.8</b> Additional Resources</a></li>
<li class="chapter" data-level="2.9" data-path="introduction-to-r.html"><a href="introduction-to-r.html#homework"><i class="fa fa-check"></i><b>2.9</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html"><i class="fa fa-check"></i><b>3</b> Exploratory Data Analysis</a>
<ul>
<li class="chapter" data-level="3.1" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#shot-logs-basketball-data"><i class="fa fa-check"></i><b>3.1</b> Shot Logs Basketball Data</a></li>
<li class="chapter" data-level="3.2" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#principal-types-of-statistical-data"><i class="fa fa-check"></i><b>3.2</b> Principal Types of Statistical Data</a></li>
<li class="chapter" data-level="3.3" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#the-distribution-of-a-data-set"><i class="fa fa-check"></i><b>3.3</b> The Distribution of a Data Set</a></li>
<li class="chapter" data-level="3.4" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#numerical-measures-for-central-tendency"><i class="fa fa-check"></i><b>3.4</b> Numerical Measures for Central Tendency</a></li>
<li class="chapter" data-level="3.5" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#numerical-measures-of-variability"><i class="fa fa-check"></i><b>3.5</b> Numerical Measures of Variability</a></li>
<li class="chapter" data-level="3.6" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#numerical-measures-for-relative-standing"><i class="fa fa-check"></i><b>3.6</b> Numerical Measures for Relative Standing</a></li>
<li class="chapter" data-level="3.7" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#relation-between-continuous-and-categorical-variables-boxplot"><i class="fa fa-check"></i><b>3.7</b> Relation between Continuous and Categorical Variables: Boxplot</a></li>
<li class="chapter" data-level="3.8" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#relation-between-continuous-variables-scatter-plots"><i class="fa fa-check"></i><b>3.8</b> Relation between Continuous Variables: Scatter Plots</a></li>
<li class="chapter" data-level="3.9" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#relationship-between-categorical-variables-contingency-tables"><i class="fa fa-check"></i><b>3.9</b> Relationship between Categorical Variables: Contingency Tables</a></li>
<li class="chapter" data-level="3.10" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#tips-and-tricks"><i class="fa fa-check"></i><b>3.10</b> Tips and Tricks</a></li>
<li class="chapter" data-level="3.11" data-path="exploratory-data-analysis.html"><a href="exploratory-data-analysis.html#homework-1"><i class="fa fa-check"></i><b>3.11</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-wrangling.html"><a href="data-wrangling.html"><i class="fa fa-check"></i><b>4</b> Data Wrangling</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-wrangling.html"><a href="data-wrangling.html#what-is-data-wrangling"><i class="fa fa-check"></i><b>4.1</b> What is Data Wrangling?</a></li>
<li class="chapter" data-level="4.2" data-path="data-wrangling.html"><a href="data-wrangling.html#nas-and-the-curse-of-real-world-data"><i class="fa fa-check"></i><b>4.2</b> NAâs and the Curse of Real World Data</a></li>
<li class="chapter" data-level="4.3" data-path="data-wrangling.html"><a href="data-wrangling.html#select-pick-only-a-few-columns"><i class="fa fa-check"></i><b>4.3</b> Select: Pick only a few columns</a></li>
<li class="chapter" data-level="4.4" data-path="data-wrangling.html"><a href="data-wrangling.html#filter-select-rows"><i class="fa fa-check"></i><b>4.4</b> Filter (select rows)</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="data-wrangling.html"><a href="data-wrangling.html#compound-criteria"><i class="fa fa-check"></i><b>4.4.1</b> Compound Criteria</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="data-wrangling.html"><a href="data-wrangling.html#chainspipes"><i class="fa fa-check"></i><b>4.5</b> Chains/Pipes %&gt;%</a></li>
<li class="chapter" data-level="4.6" data-path="data-wrangling.html"><a href="data-wrangling.html#grouping-data-together"><i class="fa fa-check"></i><b>4.6</b> Grouping Data Together</a></li>
<li class="chapter" data-level="4.7" data-path="data-wrangling.html"><a href="data-wrangling.html#homework-2"><i class="fa fa-check"></i><b>4.7</b> Homework</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="data-wrangling.html"><a href="data-wrangling.html#concept-questions-2"><i class="fa fa-check"></i><b>4.7.1</b> Concept Questions</a></li>
<li class="chapter" data-level="4.7.2" data-path="data-wrangling.html"><a href="data-wrangling.html#practice-problems-2"><i class="fa fa-check"></i><b>4.7.2</b> Practice Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html"><i class="fa fa-check"></i><b>5</b> Introduction to Clustering</a>
<ul>
<li class="chapter" data-level="5.1" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#what-is-clustering"><i class="fa fa-check"></i><b>5.1</b> What is Clustering?</a></li>
<li class="chapter" data-level="5.2" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#introduction-to-kmeans-clustering"><i class="fa fa-check"></i><b>5.2</b> Introduction to Kmeans clustering</a></li>
<li class="chapter" data-level="5.3" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#how-many-clusters-should-we-choose"><i class="fa fa-check"></i><b>5.3</b> How many clusters should we choose?</a></li>
<li class="chapter" data-level="5.4" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#clustering-nba-players"><i class="fa fa-check"></i><b>5.4</b> Clustering NBA Players</a></li>
<li class="chapter" data-level="5.5" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#requirements-for-performing-cluster-analysis"><i class="fa fa-check"></i><b>5.5</b> Requirements for Performing Cluster Analysis</a></li>
<li class="chapter" data-level="5.6" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#homework-3"><i class="fa fa-check"></i><b>5.6</b> Homework</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#concept-questions-3"><i class="fa fa-check"></i><b>5.6.1</b> Concept Questions</a></li>
<li class="chapter" data-level="5.6.2" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#practice-problems-3"><i class="fa fa-check"></i><b>5.6.2</b> Practice Problems</a></li>
<li class="chapter" data-level="5.6.3" data-path="introduction-to-clustering.html"><a href="introduction-to-clustering.html#advanced-problems-3"><i class="fa fa-check"></i><b>5.6.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Probability Theory</b></span></li>
<li class="chapter" data-level="6" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>6</b> Probability</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability.html"><a href="probability.html#sample-spaces-and-events"><i class="fa fa-check"></i><b>6.1</b> Sample Spaces and Events</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="probability.html"><a href="probability.html#introduction"><i class="fa fa-check"></i><b>6.1.1</b> Introduction</a></li>
<li class="chapter" data-level="6.1.2" data-path="probability.html"><a href="probability.html#sample-spaces"><i class="fa fa-check"></i><b>6.1.2</b> Sample Spaces</a></li>
<li class="chapter" data-level="6.1.3" data-path="probability.html"><a href="probability.html#law-of-sample-spaces"><i class="fa fa-check"></i><b>6.1.3</b> Law of Sample Spaces</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="probability.html"><a href="probability.html#combinatorics"><i class="fa fa-check"></i><b>6.2</b> Combinatorics</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability.html"><a href="probability.html#basic-principle-of-counting"><i class="fa fa-check"></i><b>6.2.1</b> Basic Principle of Counting</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability.html"><a href="probability.html#permutations"><i class="fa fa-check"></i><b>6.2.2</b> Permutations</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability.html"><a href="probability.html#combinations"><i class="fa fa-check"></i><b>6.2.3</b> Combinations</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability.html"><a href="probability.html#axioms-of-probability"><i class="fa fa-check"></i><b>6.3</b> Axioms of Probability</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="probability.html"><a href="probability.html#beyond-the-law-of-sample-spaces"><i class="fa fa-check"></i><b>6.3.1</b> Beyond the Law of Sample Spaces</a></li>
<li class="chapter" data-level="6.3.2" data-path="probability.html"><a href="probability.html#set-theory"><i class="fa fa-check"></i><b>6.3.2</b> Set Theory</a></li>
<li class="chapter" data-level="6.3.3" data-path="probability.html"><a href="probability.html#the-axioms-of-probability"><i class="fa fa-check"></i><b>6.3.3</b> The Axioms of Probability</a></li>
<li class="chapter" data-level="6.3.4" data-path="probability.html"><a href="probability.html#the-or-rule"><i class="fa fa-check"></i><b>6.3.4</b> The OR Rule</a></li>
<li class="chapter" data-level="6.3.5" data-path="probability.html"><a href="probability.html#the-and-rule"><i class="fa fa-check"></i><b>6.3.5</b> The AND Rule</a></li>
<li class="chapter" data-level="6.3.6" data-path="probability.html"><a href="probability.html#the-complement-rule"><i class="fa fa-check"></i><b>6.3.6</b> The Complement Rule</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="probability.html"><a href="probability.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>6.4</b> Conditional Probability and Independence</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="probability.html"><a href="probability.html#introduction-1"><i class="fa fa-check"></i><b>6.4.1</b> Introduction</a></li>
<li class="chapter" data-level="6.4.2" data-path="probability.html"><a href="probability.html#mathematical-definition"><i class="fa fa-check"></i><b>6.4.2</b> Mathematical Definition</a></li>
<li class="chapter" data-level="6.4.3" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>6.4.3</b> Independence</a></li>
<li class="chapter" data-level="6.4.4" data-path="probability.html"><a href="probability.html#multiplicative-rule"><i class="fa fa-check"></i><b>6.4.4</b> Multiplicative Rule</a></li>
<li class="chapter" data-level="6.4.5" data-path="probability.html"><a href="probability.html#law-of-total-probability"><i class="fa fa-check"></i><b>6.4.5</b> Law of Total Probability</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="probability.html"><a href="probability.html#bayes-rule"><i class="fa fa-check"></i><b>6.5</b> Bayes Rule</a></li>
<li class="chapter" data-level="6.6" data-path="probability.html"><a href="probability.html#homework-4"><i class="fa fa-check"></i><b>6.6</b> Homework</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="probability.html"><a href="probability.html#concept-questions-4"><i class="fa fa-check"></i><b>6.6.1</b> Concept Questions</a></li>
<li class="chapter" data-level="6.6.2" data-path="probability.html"><a href="probability.html#practice-problems-4"><i class="fa fa-check"></i><b>6.6.2</b> Practice Problems</a></li>
<li class="chapter" data-level="6.6.3" data-path="probability.html"><a href="probability.html#advanced-problems-4"><i class="fa fa-check"></i><b>6.6.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>7</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#random-variables"><i class="fa fa-check"></i><b>7.1</b> Random Variables</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distributions-for-discrete-random-variables"><i class="fa fa-check"></i><b>7.2</b> Probability Distributions for Discrete Random Variables</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#properties-of-probability-distributions"><i class="fa fa-check"></i><b>7.3</b> Properties of Probability Distributions</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expected-values-of-discrete-random-variables"><i class="fa fa-check"></i><b>7.3.1</b> Expected Values of Discrete Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#expected-value-of-sums-of-random-variables"><i class="fa fa-check"></i><b>7.4</b> Expected Value of Sums of Random Variables</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance-of-random-variables"><i class="fa fa-check"></i><b>7.5</b> Variance of Random Variables</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance-of-sums-of-random-variables"><i class="fa fa-check"></i><b>7.5.1</b> Variance of Sums of Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#bernoulli-random-variables"><i class="fa fa-check"></i><b>7.6</b> Bernoulli Random Variables</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#binomial-random-variables"><i class="fa fa-check"></i><b>7.7</b> Binomial Random Variables</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#binomial-random-variable-in-r"><i class="fa fa-check"></i><b>7.8</b> Binomial Random Variable in R</a>
<ul>
<li class="chapter" data-level="7.8.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution-in-r"><i class="fa fa-check"></i><b>7.8.1</b> Probability Distribution in R</a></li>
<li class="chapter" data-level="7.8.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#cumulative-distribution-calculations-in-r"><i class="fa fa-check"></i><b>7.8.2</b> Cumulative Distribution Calculations in R</a></li>
<li class="chapter" data-level="7.8.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#random-binomial-distribution-in-r"><i class="fa fa-check"></i><b>7.8.3</b> Random Binomial Distribution in R</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#homework-5"><i class="fa fa-check"></i><b>7.9</b> Homework</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#concept-questions-5"><i class="fa fa-check"></i><b>7.9.1</b> Concept Questions:</a></li>
<li class="chapter" data-level="7.9.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#advanced-problems-5"><i class="fa fa-check"></i><b>7.9.2</b> Advanced Problems:</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html"><i class="fa fa-check"></i><b>8</b> Continuous Random Variables</a>
<ul>
<li class="chapter" data-level="8.1" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#introduction-to-continuous-random-variables"><i class="fa fa-check"></i><b>8.1</b> Introduction to Continuous Random Variables</a></li>
<li class="chapter" data-level="8.2" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#uniform-random-variable"><i class="fa fa-check"></i><b>8.2</b> Uniform Random Variable</a></li>
<li class="chapter" data-level="8.3" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#normal-distribution"><i class="fa fa-check"></i><b>8.3</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#cumulative-distribution-function-cdf-for-normal-random-variables"><i class="fa fa-check"></i><b>8.3.1</b> Cumulative Distribution Function (CDF) for Normal Random Variables</a></li>
<li class="chapter" data-level="8.3.2" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#finding-probabilities-for-the-normal-distribution"><i class="fa fa-check"></i><b>8.3.2</b> Finding Probabilities for the Normal Distribution</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#standard-normal-distribution-z"><i class="fa fa-check"></i><b>8.4</b> Standard Normal Distribution (<span class="math inline">\(Z\)</span>)</a></li>
<li class="chapter" data-level="8.5" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#assessing-normality"><i class="fa fa-check"></i><b>8.5</b> Assessing Normality</a></li>
<li class="chapter" data-level="8.6" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#regression-to-the-mean"><i class="fa fa-check"></i><b>8.6</b> Regression to the Mean</a></li>
<li class="chapter" data-level="8.7" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#final-thoughts-on-random-variables"><i class="fa fa-check"></i><b>8.7</b> Final Thoughts on Random Variables</a></li>
<li class="chapter" data-level="8.8" data-path="continuous-random-variables.html"><a href="continuous-random-variables.html#homework-6"><i class="fa fa-check"></i><b>8.8</b> Homework</a></li>
</ul></li>
<li class="part"><span><b>III Sampling and Confidence Intervals</b></span></li>
<li class="chapter" data-level="9" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html"><i class="fa fa-check"></i><b>9</b> Introduction to Sampling Distributions</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#why-sample"><i class="fa fa-check"></i><b>9.1</b> Why Sample?</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#average-height-example"><i class="fa fa-check"></i><b>9.1.1</b> Average Height Example</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#inferences-and-point-estimators"><i class="fa fa-check"></i><b>9.2</b> Inferences and Point Estimators</a></li>
<li class="chapter" data-level="9.3" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#the-distribution-of-sample-means"><i class="fa fa-check"></i><b>9.3</b> The Distribution of Sample Means</a></li>
<li class="chapter" data-level="9.4" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#distribution-of-sample-means"><i class="fa fa-check"></i><b>9.4</b> Distribution of Sample Means</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>9.4.1</b> The Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#other-point-estimators"><i class="fa fa-check"></i><b>9.5</b> Other Point Estimators</a></li>
<li class="chapter" data-level="9.6" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#sampling-distribution-for-the-sample-proportion"><i class="fa fa-check"></i><b>9.6</b> Sampling Distribution for the Sample Proportion</a></li>
<li class="chapter" data-level="9.7" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#tales-in-sampling-poincares-baker"><i class="fa fa-check"></i><b>9.7</b> Tales in Sampling: Poincareâs Baker</a></li>
<li class="chapter" data-level="9.8" data-path="introduction-to-sampling-distributions.html"><a href="introduction-to-sampling-distributions.html#homework-7"><i class="fa fa-check"></i><b>9.8</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="confidence-intervals.html"><a href="confidence-intervals.html"><i class="fa fa-check"></i><b>10</b> Confidence Intervals</a>
<ul>
<li class="chapter" data-level="10.1" data-path="confidence-intervals.html"><a href="confidence-intervals.html#introduction-nyc-flights-dataset"><i class="fa fa-check"></i><b>10.1</b> Introduction NYC Flights Dataset</a></li>
<li class="chapter" data-level="10.2" data-path="confidence-intervals.html"><a href="confidence-intervals.html#mean-flight-delays"><i class="fa fa-check"></i><b>10.2</b> Mean Flight Delays</a></li>
<li class="chapter" data-level="10.3" data-path="confidence-intervals.html"><a href="confidence-intervals.html#shortcut-using-the-central-limit-theorem"><i class="fa fa-check"></i><b>10.3</b> Shortcut Using the Central Limit Theorem</a></li>
<li class="chapter" data-level="10.4" data-path="confidence-intervals.html"><a href="confidence-intervals.html#additional-practice-comparing-airports"><i class="fa fa-check"></i><b>10.4</b> Additional Practice: Comparing Airports</a></li>
<li class="chapter" data-level="10.5" data-path="confidence-intervals.html"><a href="confidence-intervals.html#population-proportion-confidence-intervals"><i class="fa fa-check"></i><b>10.5</b> Population Proportion Confidence Intervals</a></li>
<li class="chapter" data-level="10.6" data-path="confidence-intervals.html"><a href="confidence-intervals.html#extra-practice-problems"><i class="fa fa-check"></i><b>10.6</b> Extra Practice Problems</a></li>
<li class="chapter" data-level="10.7" data-path="confidence-intervals.html"><a href="confidence-intervals.html#homework-8"><i class="fa fa-check"></i><b>10.7</b> Homework</a></li>
</ul></li>
<li class="part"><span><b>IV Regression</b></span></li>
<li class="chapter" data-level="11" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Introduction to Linear Regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#statistical-models"><i class="fa fa-check"></i><b>11.1</b> Statistical Models</a></li>
<li class="chapter" data-level="11.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#fitting-a-linear-model-in-r"><i class="fa fa-check"></i><b>11.2</b> Fitting a Linear Model in R</a></li>
<li class="chapter" data-level="11.3" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#assumptions-of-linear-regression"><i class="fa fa-check"></i><b>11.3</b> Assumptions of Linear Regression</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#successful-linear-regression"><i class="fa fa-check"></i><b>11.3.1</b> Successful Linear Regression</a></li>
<li class="chapter" data-level="11.3.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#what-failure-looks-like"><i class="fa fa-check"></i><b>11.3.2</b> What Failure Looks Like</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>11.4</b> Goodness of Fit</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#correlation-and-slope"><i class="fa fa-check"></i><b>11.4.1</b> Correlation and Slope</a></li>
<li class="chapter" data-level="11.4.2" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#r2-coefficient-of-determination-and-measuring-model-fits"><i class="fa fa-check"></i><b>11.4.2</b> <span class="math inline">\(R^2\)</span> Coefficient of Determination and Measuring Model Fits</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#using-regression-models-to-make-predictions"><i class="fa fa-check"></i><b>11.5</b> Using Regression Models to Make Predictions</a></li>
<li class="chapter" data-level="11.6" data-path="introduction-to-linear-regression.html"><a href="introduction-to-linear-regression.html#homework-9"><i class="fa fa-check"></i><b>11.6</b> Homework</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html"><i class="fa fa-check"></i><b>12</b> Regression with Categorical Variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#introduction-2"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#one-hot-encoding"><i class="fa fa-check"></i><b>12.2</b> One Hot Encoding</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#example-exercise-and-weight"><i class="fa fa-check"></i><b>12.2.1</b> Example: Exercise and Weight</a></li>
<li class="chapter" data-level="12.2.2" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#housing-prices-by-neighborhood"><i class="fa fa-check"></i><b>12.2.2</b> Housing Prices by Neighborhood</a></li>
<li class="chapter" data-level="12.2.3" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#advanced-exercise-and-gender-together"><i class="fa fa-check"></i><b>12.2.3</b> Advanced: Exercise and Gender Together</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#diagnostics"><i class="fa fa-check"></i><b>12.3</b> Diagnostics</a></li>
<li class="chapter" data-level="12.4" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#homework-10"><i class="fa fa-check"></i><b>12.4</b> Homework</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#concept-questions-9"><i class="fa fa-check"></i><b>12.4.1</b> Concept Questions</a></li>
<li class="chapter" data-level="12.4.2" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#practice-problems-10"><i class="fa fa-check"></i><b>12.4.2</b> Practice Problems</a></li>
<li class="chapter" data-level="12.4.3" data-path="regression-with-categorical-variables.html"><a href="regression-with-categorical-variables.html#advanced-problems-10"><i class="fa fa-check"></i><b>12.4.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html"><i class="fa fa-check"></i><b>13</b> Multiple Regression Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#introduction-to-multiple-regression-models"><i class="fa fa-check"></i><b>13.1</b> Introduction to Multiple Regression Models</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#housing-prices-review-of-simple-regression-results"><i class="fa fa-check"></i><b>13.1.1</b> Housing Prices (Review of Simple Regression Results)</a></li>
<li class="chapter" data-level="13.1.2" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#multiple-regression-including-bathrooms"><i class="fa fa-check"></i><b>13.1.2</b> Multiple Regression (Including Bathrooms)</a></li>
<li class="chapter" data-level="13.1.3" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#diagnostics-for-multiple-linear-regression"><i class="fa fa-check"></i><b>13.1.3</b> Diagnostics for Multiple Linear Regression</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#multiple-regression-with-categorical-variables-including-the-neighborhood"><i class="fa fa-check"></i><b>13.2</b> Multiple Regression with Categorical Variables: Including the Neighborhood</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#predictions"><i class="fa fa-check"></i><b>13.2.1</b> Predictions</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#interactions-between-variables"><i class="fa fa-check"></i><b>13.3</b> Interactions between Variables</a></li>
<li class="chapter" data-level="13.4" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#some-pitfalls-in-multiple-regression"><i class="fa fa-check"></i><b>13.4</b> Some Pitfalls in Multiple Regression</a></li>
<li class="chapter" data-level="13.5" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#homework-11"><i class="fa fa-check"></i><b>13.5</b> Homework</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#concept-questions-10"><i class="fa fa-check"></i><b>13.5.1</b> Concept Questions</a></li>
<li class="chapter" data-level="13.5.2" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#practice-problems-11"><i class="fa fa-check"></i><b>13.5.2</b> Practice Problems</a></li>
<li class="chapter" data-level="13.5.3" data-path="multiple-regression-models.html"><a href="multiple-regression-models.html#advanced-problems-11"><i class="fa fa-check"></i><b>13.5.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Hypothesis Testing</b></span></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing: One Sample</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#introduction-and-warning"><i class="fa fa-check"></i><b>14.1</b> Introduction and Warning</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#a-starting-example"><i class="fa fa-check"></i><b>14.2</b> A Starting Example</a></li>
<li class="chapter" data-level="14.3" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#the-t.test-command-hypothesis-tests-for-the-population-mean-mu"><i class="fa fa-check"></i><b>14.3</b> The t.test command: Hypothesis Tests for the Population Mean <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="14.4" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#theory-of-hypothesis-testing"><i class="fa fa-check"></i><b>14.4</b> Theory of Hypothesis Testing</a></li>
<li class="chapter" data-level="14.5" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#under-the-hood-t-tests"><i class="fa fa-check"></i><b>14.5</b> Under the Hood (t tests)</a></li>
<li class="chapter" data-level="14.6" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>14.6</b> Errors in Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#statistical-significance-alpha"><i class="fa fa-check"></i><b>14.6.1</b> Statistical Significance (<span class="math inline">\(\alpha\)</span>)</a></li>
<li class="chapter" data-level="14.6.2" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#type-ii-error"><i class="fa fa-check"></i><b>14.6.2</b> Type II Error</a></li>
<li class="chapter" data-level="14.6.3" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#practical-significance-versus-statistical-significance"><i class="fa fa-check"></i><b>14.6.3</b> Practical Significance versus Statistical Significance</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#hypothesis-testing-for-population-fraction"><i class="fa fa-check"></i><b>14.7</b> Hypothesis Testing for Population Fraction</a>
<ul>
<li class="chapter" data-level="14.7.1" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#example-3"><i class="fa fa-check"></i><b>14.7.1</b> Example:</a></li>
</ul></li>
<li class="chapter" data-level="14.8" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#hypothesis-testing-in-linear-regression"><i class="fa fa-check"></i><b>14.8</b> Hypothesis Testing in Linear Regression</a></li>
<li class="chapter" data-level="14.9" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#power-of-a-statistical-test"><i class="fa fa-check"></i><b>14.9</b> Power of a Statistical Test</a></li>
<li class="chapter" data-level="14.10" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#homework-12"><i class="fa fa-check"></i><b>14.10</b> Homework</a>
<ul>
<li class="chapter" data-level="14.10.1" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#concept-questions-11"><i class="fa fa-check"></i><b>14.10.1</b> Concept Questions:</a></li>
<li class="chapter" data-level="14.10.2" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#practice-problems-12"><i class="fa fa-check"></i><b>14.10.2</b> Practice Problems:</a></li>
<li class="chapter" data-level="14.10.3" data-path="hypothesis-testing-one-sample.html"><a href="hypothesis-testing-one-sample.html#advanced-problems-12"><i class="fa fa-check"></i><b>14.10.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html"><i class="fa fa-check"></i><b>15</b> Hypothesis Testing: Two Sample Tests</a>
<ul>
<li class="chapter" data-level="15.1" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#two-sample-t-test"><i class="fa fa-check"></i><b>15.1</b> Two Sample t test</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#regression-analysis"><i class="fa fa-check"></i><b>15.1.1</b> Regression analysis</a></li>
<li class="chapter" data-level="15.1.2" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#two-sample-t-test-approach"><i class="fa fa-check"></i><b>15.1.2</b> Two Sample t test approach</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#two-sample-proportion-tests"><i class="fa fa-check"></i><b>15.2</b> Two Sample Proportion Tests</a></li>
<li class="chapter" data-level="15.3" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#extra-example-birth-weights-and-smoking"><i class="fa fa-check"></i><b>15.3</b> Extra Example: Birth Weights and Smoking</a></li>
<li class="chapter" data-level="15.4" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#homework-13"><i class="fa fa-check"></i><b>15.4</b> Homework</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#concept-questions-12"><i class="fa fa-check"></i><b>15.4.1</b> Concept Questions</a></li>
<li class="chapter" data-level="15.4.2" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#practice-problems-13"><i class="fa fa-check"></i><b>15.4.2</b> Practice Problems</a></li>
<li class="chapter" data-level="15.4.3" data-path="hypothesis-testing-two-sample-tests.html"><a href="hypothesis-testing-two-sample-tests.html#advanced-problems-13"><i class="fa fa-check"></i><b>15.4.3</b> Advanced Problems</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="confidence-intervals-and-hypothesis-testing.html"><a href="confidence-intervals-and-hypothesis-testing.html"><i class="fa fa-check"></i><b>16</b> Confidence Intervals and Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="16.1" data-path="confidence-intervals-and-hypothesis-testing.html"><a href="confidence-intervals-and-hypothesis-testing.html#relation-to-confidence-intervals"><i class="fa fa-check"></i><b>16.1</b> Relation to Confidence Intervals</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="confidence-intervals-and-hypothesis-testing.html"><a href="confidence-intervals-and-hypothesis-testing.html#two-sided-tests"><i class="fa fa-check"></i><b>16.1.1</b> Two sided tests</a></li>
<li class="chapter" data-level="16.1.2" data-path="confidence-intervals-and-hypothesis-testing.html"><a href="confidence-intervals-and-hypothesis-testing.html#one-sided-confidence-intervals"><i class="fa fa-check"></i><b>16.1.2</b> One-sided confidence intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html"><i class="fa fa-check"></i><b>17</b> Introduction to the Chi Square Test</a>
<ul>
<li class="chapter" data-level="17.1" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#contingency-tables"><i class="fa fa-check"></i><b>17.1</b> Contingency Tables</a></li>
<li class="chapter" data-level="17.2" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#chi-square-test"><i class="fa fa-check"></i><b>17.2</b> Chi Square Test</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#conditions-for-using-the-chi2-test"><i class="fa fa-check"></i><b>17.2.1</b> Conditions for Using the <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="17.2.2" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#multiple-hypothesis-testing-again"><i class="fa fa-check"></i><b>17.2.2</b> Multiple Hypothesis Testing Again</a></li>
<li class="chapter" data-level="17.2.3" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#using-a-different-null-hypothesis"><i class="fa fa-check"></i><b>17.2.3</b> Using a different Null Hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="introduction-to-the-chi-square-test.html"><a href="introduction-to-the-chi-square-test.html#homework-14"><i class="fa fa-check"></i><b>17.3</b> Homework</a></li>
</ul></li>
<li class="part"><span><b>VI Advanced Regression Topics</b></span></li>
<li class="chapter" data-level="18" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>18</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="18.1" data-path="logistic-regression.html"><a href="logistic-regression.html#what-is-logistic-regression-used-for"><i class="fa fa-check"></i><b>18.1</b> What is logistic regression used for?</a></li>
<li class="chapter" data-level="18.2" data-path="logistic-regression.html"><a href="logistic-regression.html#glm-generalized-linear-models"><i class="fa fa-check"></i><b>18.2</b> GLM: Generalized Linear Models</a></li>
<li class="chapter" data-level="18.3" data-path="logistic-regression.html"><a href="logistic-regression.html#a-starting-example-1"><i class="fa fa-check"></i><b>18.3</b> A Starting Example</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="logistic-regression.html"><a href="logistic-regression.html#confidence-intervals-for-the-parameters"><i class="fa fa-check"></i><b>18.3.1</b> Confidence Intervals for the Parameters</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="logistic-regression.html"><a href="logistic-regression.html#equivalence-of-logistic-regression-and-proportion-tests"><i class="fa fa-check"></i><b>18.4</b> Equivalence of Logistic Regression and Proportion Tests</a></li>
<li class="chapter" data-level="18.5" data-path="logistic-regression.html"><a href="logistic-regression.html#example-building-a-more-accurate-model"><i class="fa fa-check"></i><b>18.5</b> Example: Building a More Accurate Model</a></li>
<li class="chapter" data-level="18.6" data-path="logistic-regression.html"><a href="logistic-regression.html#example-measuring-team-defense-using-logistic-regression"><i class="fa fa-check"></i><b>18.6</b> Example: Measuring Team Defense Using Logistic Regression</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Statistics and Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-regression-models" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">Chapter 13</span> Multiple Regression Models<a href="multiple-regression-models.html#multiple-regression-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introduction-to-multiple-regression-models" class="section level2 hasAnchor" number="13.1">
<h2><span class="header-section-number">13.1</span> Introduction to Multiple Regression Models<a href="multiple-regression-models.html#introduction-to-multiple-regression-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have learned about simple linear regression where we have a single explanatory and response variable, which we assume are related in a linear manner. This gives us a model of the form: <span class="math display">\[ y=\alpha+\beta x+\epsilon_i\]</span> where <span class="math inline">\(y\)</span> is our response variable, <span class="math inline">\(x\)</span> is the explanatory variable. The parameters <span class="math inline">\((\alpha, \beta)\)</span> the y-intercept and slope respectively are fit to the data to minimize the least-square error. Finally, the term <span class="math inline">\(\epsilon_i\)</span> is the random noise which is assumed to be Gaussian (Normal) distributed with equal variance.</p>
<p>However, in analyzing data we are often interested in building a model for a system where more than one input of explanatory variable may be important. For example, when building a model to predict the value of a stock-price we would want to include several economics indicators (market measures, GDP, etc). To build a model of the size of the freshman class at Schreiner we would want to include many factors such as the number of high school graduates in the area, economic health of Texas, etc.</p>
<p>Models with more than one explanatory variable are called <strong>multiple regression models</strong>. They take the general form:
<span class="math display">\[ y=\alpha+\beta_1 x_1+\beta_2 x_2+...+\beta_n x_n+\epsilon_i \]</span>
Often the most important decision to make when building a multiple regression model is deciding what explanatory variables <span class="math inline">\((x_1, x_2, ... x_n)\)</span> to include in the model. It is sometimes tempting to just include everything that you feel might be relevant. However, this will lead to very complex models which are difficult to interpret, and can lead to exceptionally poor models due to the dangerous condition called <strong>over-fitting</strong>. A model which has been over-fit can be exceedingly dangerous as it will appear to be very precise when considering the collected data but may generate exceptionally poor estimates when used to make new predictions.</p>
<p>A key decision in building a regression model is to deciding what variables to include in the model.</p>
<p>The starting point for this decision should always be common sense. You should never include an explanatory variable which you donât have good reason to suspect will have any effect on the response variable (output). For example, if we are building a model to predict the Schreiner freshman class size, it would make no sense to include an explanatory variable of the number of ice cream cones sold in Texas the previous year. Ice cream sales should be totally unrelated to the freshman class size, so anything we find would likely be spurious.</p>
<p>We also need to ensure that any explanatory variables we include are at least approximately linearly related to the response variable. We checked for this in simple linear regression using a scatter plot of x versus y. If this scatter plot looks roughly like a line then it makes sense to build a simple regression model.</p>
<p>For multiple regression we have a simple plot we can make to look for relationships between our variables. To make this plot we need to be considering numeric variables (just like a scatter plot), therefore in the below command I am using the command <code>grabNumeric</code> from my package. This takes a data frame (spreadsheet) and removes any categorical variables from it, leaving only the numeric values.</p>

<div class="note">
Models can also suffer from a condition known as <strong>underfitting</strong> this occurs when some significant explanatory variable(s) are not included in the model. This to can lead to poor predictions when use to predict new data.
</div>
<p>For these notes I will be using the Ames Housing data set from my package. The columns of this data set are:</p>
<div class="sourceCode" id="cb528"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb528-1"><a href="multiple-regression-models.html#cb528-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(AmesHousing_Regression)</span></code></pre></div>
<pre><code>## [1] &quot;Square.Feet.log10&quot; &quot;SalePrice.log10&quot;   &quot;Neighborhood&quot;     
## [4] &quot;Bathroom&quot;</code></pre>
<p>The Neighborhood column is categorical, the others are numeric. The goal is to build a model which can predict the sales price of a house using the SQFT, Bathrooms and Neighborhood information. It makes logical sense that the size, number of bathrooms and neighborhood would each effect the sales price of a house.</p>
<div class="sourceCode" id="cb530"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb530-1"><a href="multiple-regression-models.html#cb530-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">grabNumeric</span>(AmesHousing_Regression), <span class="at">cex =</span> <span class="fl">0.3</span>, <span class="at">main =</span> <span class="st">&quot;Multiple Regression EDA&quot;</span>,</span>
<span id="cb530-2"><a href="multiple-regression-models.html#cb530-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> <span class="st">&quot;lightblue&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-481-1.png" width="672" /></p>
<p>This plot shows the relationship between each of these factors and the sales price, and also looks for relationships between the variables themselves. Since we have three numeric variables here we get a 3 by 3 grid of plots. The plot in the first row, second column shows the SQFT on the y-axis and the sales price on the x-axis (notice how you can see this from looking at the diagonal labels).</p>
<p>Now that we know how to read this plot, what are we looking for? Well first, we want to check if our response variable (sales price) at least approximately linearly depends on the explanatory variables (bathrooms and SQFT). This is shown in the 2nd row of our grid. Each of these look roughly like we could fit a line to the trends.</p>
<p>The next thing we want to look for is any strong relationships between our explanatory variables (SQFT and Bathrooms). This is shown in row 1, column 3 as bathrooms versus SQFT and in row 3, column 1 as SQFT vs bathrooms. From these graphs it looks like we have a pretty solid relationship between the number of bathrooms and the square feet of the house. This also makes some logical sense as bigger houses usually have more bathrooms.</p>
<p>This relationship between these two variables means that we should really only include one of them in our multiple regression model. This condition is called <strong>multicollinearity</strong> between these two variables. In general, this is a bad thing and this means we really shouldnât include both of these variables together in our regression models (we will ignore this below for the sake of demonstration).</p>
<p>Practically, this means that adding bathrooms to our model wonât really improve our predictions much: if we know the square footage we have a pretty good idea of the bathrooms already.</p>
<p>We can also get an idea of the <strong>multicollinearity</strong> of our model using a correlation matrix. Here we find the linear correlation between all sets of variables in the data set. The correlation is a numerical measure of how much our scatter plot looks like a line. It will range between the values of [-1,1] with positive one meaning all the data lies along a perfect line with positive slope and -1 meaning the data lies along a line with a negative slope (decreasing relationship)</p>
<p>The below code forms a correlation matrix for the housing data.</p>
<div class="sourceCode" id="cb531"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb531-1"><a href="multiple-regression-models.html#cb531-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(<span class="fu">grabNumeric</span>(AmesHousing_Regression))</span></code></pre></div>
<pre><code>##                   Square.Feet.log10 SalePrice.log10  Bathroom
## Square.Feet.log10         1.0000000       0.7231662 0.7330792
## SalePrice.log10           0.7231662       1.0000000 0.6161632
## Bathroom                  0.7330792       0.6161632 1.0000000</code></pre>
<p>As you can see all of these variables are positively related. The diagonal values will always be all ones, as every variable is perfectly correlated with itself.</p>
<p>We can form a graphical version of this correlation matrix using:</p>
<div class="sourceCode" id="cb533"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb533-1"><a href="multiple-regression-models.html#cb533-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(corrplot)</span>
<span id="cb533-2"><a href="multiple-regression-models.html#cb533-2" aria-hidden="true" tabindex="-1"></a><span class="fu">corrplot</span>(<span class="fu">cor</span>(<span class="fu">grabNumeric</span>(AmesHousing_Regression)))</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-483-1.png" width="672" /></p>
<p>You may need to run the command:</p>
<div class="sourceCode" id="cb534"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb534-1"><a href="multiple-regression-models.html#cb534-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;corrplot&quot;</span>)</span></code></pre></div>
<p>to be able to make a correlation plot yourself. You will only need to do this one time.</p>

<div class="fallacy">
<p>Mutual funds are created by bundling a bunch of individual stocks together. The idea is that budling the stocks together will can average out some of the flucuations and get a lower risk investment. However, someone needs to choose exactly which stocks to include in the fund and how much money should be invested in each companies stock. Typically, stock traders will design a mutual fund and record how well it would have done in the market for some trial period (say 1 year), then the proposed mutual funds which perform best over that trial period are offered to investors for us to put our money in. Typically, they will advertise the average return of the mutual fund achieved during the trial period. Most of the time these funds will have very impressive returns.</p>
However, once the investors put their money into the funds they typically do significantly worse then the rates first reported. We can understand this as thinking of the trial period as <em>fitting</em> the models. The limited amout of data in the trial period makes it very easy to overfit the model. Thus, the predictions quickly become inaccurate when we move outside the trial period.
</div>

<div class="advanced">
We do not have the time to properly discuss under/over fitting for models in this course. However, when statistical models are built to make real world predictions generally the modeler will break their data into a training and test set. The train data is used to build the model and the test data is NEVER used in building the model. Finially, when the modeler wants to see how good of a predictive model they have built they use the test data to generate predictions and see how well the model does using data it has never seen before.
</div>
<p>##Building a Multiple Regression Model</p>
<div id="housing-prices-review-of-simple-regression-results" class="section level3 hasAnchor" number="13.1.1">
<h3><span class="header-section-number">13.1.1</span> Housing Prices (Review of Simple Regression Results)<a href="multiple-regression-models.html#housing-prices-review-of-simple-regression-results" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Letâs return to the housing data set and see if we can improve our model by including some additional factors. In the simple linear regression notes we used linear regression to understand the relationship between the sales price of a house and the square footage of that house. The data set comes from Ames, Iowa house sales from 2006-2010. First, lets read this data in and make a scatter plot of the sales price versus the square footage.</p>
<div class="sourceCode" id="cb535"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb535-1"><a href="multiple-regression-models.html#cb535-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;AmesHousing_Regression&quot;</span>)  <span class="do">##from HannayAppliedStats package</span></span>
<span id="cb535-2"><a href="multiple-regression-models.html#cb535-2" aria-hidden="true" tabindex="-1"></a>house <span class="ot">&lt;-</span> AmesHousing_Regression  <span class="do">##rename this data</span></span>
<span id="cb535-3"><a href="multiple-regression-models.html#cb535-3" aria-hidden="true" tabindex="-1"></a>house <span class="ot">&lt;-</span> <span class="fu">dropLowFactors</span>(house, <span class="at">factor.column =</span> <span class="dv">3</span>, <span class="at">threshold =</span> <span class="dv">30</span>)  <span class="do">##from HannayApplied Stats drop all neighborhoods with less than 30 data points</span></span>
<span id="cb535-4"><a href="multiple-regression-models.html#cb535-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(house)</span></code></pre></div>
<pre><code>##   Square.Feet.log10 SalePrice.log10 Neighborhood Bathroom
## 1          3.219060        5.332438        NAmes      1.0
## 2          2.952308        5.021189        NAmes      1.0
## 3          3.123525        5.235528        NAmes      1.5
## 4          3.324282        5.387390        NAmes      2.5
## 5          3.211921        5.278525      Gilbert      2.5
## 6          3.205204        5.291147      Gilbert      2.5</code></pre>
<p>We can see this has the log10 of the selling price, the square footage and the number of bathrooms in the house.</p>
<div class="sourceCode" id="cb537"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb537-1"><a href="multiple-regression-models.html#cb537-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(house<span class="sc">$</span>Square.Feet, house<span class="sc">$</span>SalePrice, <span class="at">main =</span> <span class="st">&quot;Real Estate Prices in Ames Iowa (Color by Neighborhood)&quot;</span>,</span>
<span id="cb537-2"><a href="multiple-regression-models.html#cb537-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;Square Footage (log10)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Sale Price ($) log10&quot;</span>, <span class="at">col =</span> house<span class="sc">$</span>Neighborhood,</span>
<span id="cb537-3"><a href="multiple-regression-models.html#cb537-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-488-1.png" width="672" /></p>
<p>As expected we can see from the plot that square footage is somewhat important in determining the sales price of the house, but we can see that their is significant variation in the sales price for any given sqft size. Letâs try and build a linear model for the relationship between the sqft of the houses and the sales price.</p>
<div class="sourceCode" id="cb538"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb538-1"><a href="multiple-regression-models.html#cb538-1" aria-hidden="true" tabindex="-1"></a>res.house <span class="ot">=</span> <span class="fu">lm</span>(SalePrice.log10 <span class="sc">~</span> Square.Feet.log10, <span class="at">data =</span> house)</span>
<span id="cb538-2"><a href="multiple-regression-models.html#cb538-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(res.house)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SalePrice.log10 ~ Square.Feet.log10, data = house)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.89909 -0.06464  0.01245  0.07581  0.37552 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        2.33795    0.05115   45.71   &lt;2e-16 ***
## Square.Feet.log10  0.91365    0.01620   56.38   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1225 on 2832 degrees of freedom
## Multiple R-squared:  0.5289, Adjusted R-squared:  0.5287 
## F-statistic:  3179 on 1 and 2832 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>As we saw in the simple linear regression notes this is a fine model for the sales price, but notice the goodness of fit measurement <span class="math inline">\(R^2\)</span> is only about 0.52. This means that we cannot precisely predict the selling price of a house given only the square footage. This makes sense practically as we expect the size of a house to be important, but many other factors will effect the price.</p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="multiple-regression-models.html#cb540-1" aria-hidden="true" tabindex="-1"></a><span class="fu">diagRegressionPlots</span>(res.house, <span class="at">cex =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-490-1.png" width="672" /></p>
<p>Multiple regression allows us to include some more information for our regression model to use in the predictions.</p>
</div>
<div id="multiple-regression-including-bathrooms" class="section level3 hasAnchor" number="13.1.2">
<h3><span class="header-section-number">13.1.2</span> Multiple Regression (Including Bathrooms)<a href="multiple-regression-models.html#multiple-regression-including-bathrooms" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To improve our model we might want to also include the number of bathrooms in the house. Thus our model to the sales price of a house becomes <span class="math display">\[ \log_{10}(SP)=\alpha+\beta_1 \log_{10}(SQFT)+\beta_2 BATH, \]</span> where <span class="math inline">\(SP\)</span> is the sales price of the house.</p>
<p>We can get an idea graphically about the combined effect of bathrooms and square footage of the house by making a colored scatter plot of this data:</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="multiple-regression-models.html#cb541-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(house<span class="sc">$</span>Square.Feet.log10, house<span class="sc">$</span>SalePrice.log10, <span class="at">col =</span> house<span class="sc">$</span>Bathroom, <span class="at">cex =</span> <span class="fl">0.4</span>,</span>
<span id="cb541-2"><a href="multiple-regression-models.html#cb541-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">main =</span> <span class="st">&quot;Sqft versus Sales Price colored by number of Bathrooms&quot;</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-491-1.png" width="672" /></p>
<p><code>R</code> makes it very easy to build our multiple linear regression model.</p>
<div class="sourceCode" id="cb542"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb542-1"><a href="multiple-regression-models.html#cb542-1" aria-hidden="true" tabindex="-1"></a>mlm.house.bath <span class="ot">=</span> <span class="fu">lm</span>(SalePrice.log10 <span class="sc">~</span> Square.Feet.log10 <span class="sc">+</span> Bathroom, <span class="at">data =</span> house)</span>
<span id="cb542-2"><a href="multiple-regression-models.html#cb542-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mlm.house.bath)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SalePrice.log10 ~ Square.Feet.log10 + Bathroom, 
##     data = house)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.90090 -0.06028  0.00606  0.07294  0.40973 
## 
## Coefficients:
##                   Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       2.828511   0.068014   41.59   &lt;2e-16 ***
## Square.Feet.log10 0.727309   0.023599   30.82   &lt;2e-16 ***
## Bathroom          0.055399   0.005187   10.68   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.1201 on 2831 degrees of freedom
## Multiple R-squared:  0.5471, Adjusted R-squared:  0.5468 
## F-statistic:  1710 on 2 and 2831 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>For now letâs figure out how we can interpret these results. <em>Note ignore the hypothesis testing components of this during the first reading, we will cover that next.</em></p>
<ol style="list-style-type: decimal">
<li><p>First, we can look at the last line of the summary: âF-statistic: 1710 on 2 and 2831 DF, p-value: &lt; 2.2e-16â. This tells us the results of a statistical test to see if sqft and bathrooms tell us <strong>anything</strong> about the sales price. The null hypothesis of the <strong>F-test</strong> is that the explanatory variables (sqft, bathrooms) donât inform us at all about the response variable (sales price). The low p-value here tells us we can reject that null hypothesis.</p></li>
<li><p>Notice that the <span class="math inline">\(R^2\)</span> value increased by a small amount (to about <span class="math inline">\(0.55\)</span> from <span class="math inline">\(0.52\)</span>). This indicates that adding the bathroom information allowed us to make slightly more precise predictions. This is probably not as much as we were hoping for as an increase. This will very often be the case when you are building a multiple regression model (more about this later). We also should anticipate this based on our EDA, knowing the size of a house tells you roughly how many bathrooms it has, so including the number of bathrooms doesnât give the model much more information to work with.</p></li>
<li><p>Recall that a slope of zero for an explanatory variable means it has no effect on the response variable. We can study the effect of a variable on the sales price by forming the confidence intervals for the coefficients:</p></li>
</ol>
<div class="sourceCode" id="cb544"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb544-1"><a href="multiple-regression-models.html#cb544-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mlm.house.bath, <span class="at">level =</span> <span class="fl">0.99</span>)</span></code></pre></div>
<pre><code>##                        0.5 %     99.5 %
## (Intercept)       2.65319991 3.00382163
## Square.Feet.log10 0.66647946 0.78813805
## Bathroom          0.04202894 0.06876991</code></pre>
<p>None of these are really close to zero, meaning that each of these factors effects the response variable (sales price).</p>
<ol start="4" style="list-style-type: decimal">
<li>Letâs fill in our best-fit model to help interpret the values of the coefficients:
<span class="math display">\[ \log_{10}(SP)=2.828+0.727\log_{10}(SQFT)+0.055 BATH .\]</span> This tells us we can expect the log10 of the price to increase by about 0.72 for every time the log10 sqft increases by one and the number of bathrooms is constant. For houses with the same square footage but one of them has 1.0 additional bathrooms we can expect the log10 sales price of the house with the additional bathroom to be about 0.055 more.</li>
</ol>
<p>In general, we can interpret these coefficients in a similar way we did for the simple linear regression, increase of the explanatory variable by one unit causes a <strong>slope</strong> increase in the response variable. The main difference is that we have to say, <strong>holding the other explanatory variable constant or fixed</strong>.</p>
<p>These interpretations are a bit messy from a practical standpoint though because of the logarithms. We can get rid of the logarithms now by taking each side of this equation to the power of 10.
<span class="math display">\[10^{\log_{10}(SP)}=10^{2.828+0.727\log_{10}(SQFT)+0.055*BATH } \iff SP=10^{2.828} 10^{0.727\log_{10}(SQFT)} 10^{0.055 BATH}\]</span>
This gives us the best fit model:</p>
<p><span class="math display">\[SP=660.89(SQFT)^{0.727}(1.135)^{BATH}\]</span>
We could then use this formula to help predict the sales price of a house in dollars. For example, the model predicts the average house with 2000 square feet and 2 bathrooms would sell for about: 218,000 dollars. Of course the relatively low <span class="math inline">\(R^2\)</span> value (high residual standard error) tells us to expect significant variation about this estimate in practice.</p>
<p>We can get an idea on the certainty of our predictions using prediction intervals (just like we did for simple regression)</p>
<div class="sourceCode" id="cb546"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb546-1"><a href="multiple-regression-models.html#cb546-1" aria-hidden="true" tabindex="-1"></a>predict.sales <span class="ot">=</span> <span class="fu">predict</span>(mlm.house.bath, <span class="fu">data.frame</span>(<span class="at">Square.Feet.log10 =</span> <span class="fu">c</span>(<span class="fu">log10</span>(<span class="dv">2000</span>)),</span>
<span id="cb546-2"><a href="multiple-regression-models.html#cb546-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">Bathroom =</span> <span class="fu">c</span>(<span class="dv">2</span>)), <span class="at">interval =</span> <span class="st">&quot;predict&quot;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb546-3"><a href="multiple-regression-models.html#cb546-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="dv">10</span><span class="sc">^</span>predict.sales)</span></code></pre></div>
<pre><code>##        fit      lwr    upr
## 1 218865.7 127222.5 376523</code></pre>
<p>This gives a huge range or 127k to 376k as a predicted sales price for our 2000 sqft, 2 bedroom house. This is because houses with the same square footage and bathrooms can vary a lot!</p>
</div>
<div id="diagnostics-for-multiple-linear-regression" class="section level3 hasAnchor" number="13.1.3">
<h3><span class="header-section-number">13.1.3</span> Diagnostics for Multiple Linear Regression<a href="multiple-regression-models.html#diagnostics-for-multiple-linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The assumptions of simple least squares regression carry over to multiple linear regression. We can check these by using our diagRegressionPlots command:</p>
<div class="sourceCode" id="cb548"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb548-1"><a href="multiple-regression-models.html#cb548-1" aria-hidden="true" tabindex="-1"></a><span class="fu">diagRegressionPlots</span>(mlm.house.bath, <span class="at">cex =</span> <span class="fl">0.3</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-495-1.png" width="672" />
These can be interpreted in the same way as simple linear regression, except for the bottom right plot which is pretty meaningless for a multiple regression plot. <strong>You should ignore this bottom right plot for multiple regression plots.</strong></p>
<p>We will go over some additional <strong>pitfalls</strong> of multiple linear regression at the bottom of these notes. In general, you will see that multiple regression opens a statistical can of worms which just isnât present for simple regression. However, in many cases this additional pain is worth the effort to obtain better predictions.</p>
</div>
</div>
<div id="multiple-regression-with-categorical-variables-including-the-neighborhood" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> Multiple Regression with Categorical Variables: Including the Neighborhood<a href="multiple-regression-models.html#multiple-regression-with-categorical-variables-including-the-neighborhood" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>I am no real estate expert, but I do know that the location and neighborhood of a house can make a huge difference in the sales price. I believe real-estate agents have a saying âLocation, Location, Locationâ. Therefore we might want to include the neighborhood information into our prediction model for the sales price.</p>
<p>The below plot shows the sales price versus square footage colored by the neighborhood.</p>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="multiple-regression-models.html#cb549-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(house<span class="sc">$</span>Square.Feet, house<span class="sc">$</span>SalePrice, <span class="at">main =</span> <span class="st">&quot;Real Estate Prices in Ames Iowa (Color by Neighborhood)&quot;</span>,</span>
<span id="cb549-2"><a href="multiple-regression-models.html#cb549-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;Square Footage (log10)&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;Sale Price ($) log10&quot;</span>, <span class="at">col =</span> house<span class="sc">$</span>Neighborhood,</span>
<span id="cb549-3"><a href="multiple-regression-models.html#cb549-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">cex =</span> <span class="fl">0.5</span>)</span></code></pre></div>
<p><img src="statsbook_files/figure-html/unnamed-chunk-496-1.png" width="672" /></p>
<p>We have seen that we can include a categorical variable into a regression model using One Hot Encoding. The levels of the Neighborhood variable are.</p>
<div class="sourceCode" id="cb550"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb550-1"><a href="multiple-regression-models.html#cb550-1" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(house<span class="sc">$</span>Neighborhood)</span></code></pre></div>
<pre><code>##  [1] &quot;BrDale&quot;  &quot;BrkSide&quot; &quot;ClearCr&quot; &quot;CollgCr&quot; &quot;Crawfor&quot; &quot;Edwards&quot; &quot;Gilbert&quot;
##  [8] &quot;IDOTRR&quot;  &quot;MeadowV&quot; &quot;Mitchel&quot; &quot;NAmes&quot;   &quot;NoRidge&quot; &quot;NridgHt&quot; &quot;NWAmes&quot; 
## [15] &quot;OldTown&quot; &quot;Sawyer&quot;  &quot;SawyerW&quot; &quot;Somerst&quot; &quot;StoneBr&quot; &quot;SWISU&quot;   &quot;Timber&quot;</code></pre>
<p>Letâs see what happens when we build a model for the sales price which includes the <em>neighborhood and the square footage</em>.</p>
<div class="sourceCode" id="cb552"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb552-1"><a href="multiple-regression-models.html#cb552-1" aria-hidden="true" tabindex="-1"></a>mlm.house.neigh <span class="ot">=</span> <span class="fu">lm</span>(SalePrice.log10 <span class="sc">~</span> Square.Feet.log10 <span class="sc">+</span> Neighborhood, <span class="at">data =</span> house)</span>
<span id="cb552-2"><a href="multiple-regression-models.html#cb552-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mlm.house.neigh)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SalePrice.log10 ~ Square.Feet.log10 + Neighborhood, 
##     data = house)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.83000 -0.04523  0.00652  0.05027  0.34430 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)          3.080125   0.044304  69.522  &lt; 2e-16 ***
## Square.Feet.log10    0.637562   0.013591  46.910  &lt; 2e-16 ***
## NeighborhoodBrkSide  0.039085   0.017923   2.181   0.0293 *  
## NeighborhoodClearCr  0.167238   0.020711   8.075 9.93e-16 ***
## NeighborhoodCollgCr  0.197114   0.016790  11.740  &lt; 2e-16 ***
## NeighborhoodCrawfor  0.162755   0.018174   8.955  &lt; 2e-16 ***
## NeighborhoodEdwards  0.037740   0.017049   2.214   0.0269 *  
## NeighborhoodGilbert  0.152508   0.017368   8.781  &lt; 2e-16 ***
## NeighborhoodIDOTRR  -0.046408   0.018231  -2.545   0.0110 *  
## NeighborhoodMeadowV -0.026506   0.021337  -1.242   0.2142    
## NeighborhoodMitchel  0.136953   0.017836   7.679 2.20e-14 ***
## NeighborhoodNAmes    0.099158   0.016395   6.048 1.66e-09 ***
## NeighborhoodNoRidge  0.264670   0.019472  13.592  &lt; 2e-16 ***
## NeighborhoodNridgHt  0.319502   0.017514  18.242  &lt; 2e-16 ***
## NeighborhoodNWAmes   0.137457   0.017725   7.755 1.23e-14 ***
## NeighborhoodOldTown -0.005045   0.016856  -0.299   0.7647    
## NeighborhoodSawyer   0.100314   0.017356   5.780 8.31e-09 ***
## NeighborhoodSawyerW  0.137109   0.017759   7.721 1.60e-14 ***
## NeighborhoodSomerst  0.229748   0.017236  13.330  &lt; 2e-16 ***
## NeighborhoodStoneBr  0.315992   0.020214  15.632  &lt; 2e-16 ***
## NeighborhoodSWISU    0.007000   0.020300   0.345   0.7302    
## NeighborhoodTimber   0.239228   0.019028  12.572  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.08683 on 2812 degrees of freedom
## Multiple R-squared:  0.7649, Adjusted R-squared:  0.7632 
## F-statistic: 435.7 on 21 and 2812 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>This is a much longer output. However, letâs start at the bottom as before. Once again ignore the statistical hypothesis testing stuff on the first reading.</p>
<ol style="list-style-type: decimal">
<li><p>The F test given on the last line tells us that overall that the neighborhood and square footage indeed are associated with the sales price.</p></li>
<li><p>The <span class="math inline">\(R^2\)</span> value has increased by a fair amount. Thus, our model is likely a better predictor.</p></li>
<li><p>Now lets look at the coefficients. You will notice we have a lot more of them! Also notice that every neighborhood is listed except the first one âBrDaleâ. When we give a categorical variable to <code>R</code> with <span class="math inline">\(N\)</span> levels (options the categorical variable can take) it will automatically convert this into <span class="math inline">\(N-1\)</span> âdummy variablesâ. These dummy variables are 1 if the house is in that neighborhood and 0 if it is not. So under the hood <code>R</code> is using a model of the form: <span class="math display">\[ \log_{10}(SP)=\alpha+\beta_1 \log_{10}(SQFT)+\beta_2 BrkSide+ \beta_3 ClearCr+\beta_4 CollfCr+....+ \beta_{N-1} Timber.\]</span></p></li>
</ol>
<p>Where the neighborhood explanatory variables BrkSide, â¦ Timber are either 1 or 0. So we are basically fitting a different model for each neighborhood. For example our model for houses in the BrkSide neighborhood is: <span class="math display">\[\log_{10}(SP)=3.08+0.6375 \log_{10}(SQFT)+0.039085\]</span> for houses in ClearCtr it is: <span class="math display">\[\log_{10}(SP)=3.08+0.6375 \log_{10}(SQFT)+0.167238\]</span>
Notice this is because once we know the neighborhood of a house all the other neighborhood dummy variables are zero.</p>
<ol start="4" style="list-style-type: decimal">
<li><p>What happened to the first neighborhood âBrDaleâ? Well, if a house is in BrDale then it is not in any of the other neighborhoods so all those dummy variables are zero. So our model for houses in âBrDaleâ is just:<span class="math display">\[ \log_{10}(SP)=3.08+0.6375 \log_{10}(SQFT) \]</span></p></li>
<li><p>Now that we know where âBrDaleâ went we can get a better interpretation of what the values of the neighborhood coefficients are. If they are positive it means that houses in that neighborhood (of the same square footage) will tend to sell for more money. If they are negative then the reverse is true. You can see that most of the neighborhoods are positive relative to âBrDaleâ meaning that perhaps BrDale is not a desirable neighborhood for some reason. Mathematically, our models we are building for each neighborhood differ only in terms of the y-intercept value. They are a bunch of parallel lines shifted vertically from one another.</p></li>
</ol>

<div class="note">
<p>In a simple scenario like this we can avoid the <em>dummy</em> variable interpretation by changing our regression formula to include a <code>+0</code> part. This tells R to remove the intercept from the fit. Notice that this model has all the neighborhoods listed.</p>
</div>
<p>Here is the <code>R</code> code where we have removed the intercept term. Notice that all neighborhoods appear now.</p>
<div class="sourceCode" id="cb554"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb554-1"><a href="multiple-regression-models.html#cb554-1" aria-hidden="true" tabindex="-1"></a>mlm.house.neigh.all <span class="ot">=</span> <span class="fu">lm</span>(SalePrice.log10 <span class="sc">~</span> Square.Feet.log10 <span class="sc">+</span> Neighborhood <span class="sc">+</span> <span class="dv">0</span>,</span>
<span id="cb554-2"><a href="multiple-regression-models.html#cb554-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> house)</span>
<span id="cb554-3"><a href="multiple-regression-models.html#cb554-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mlm.house.neigh.all)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SalePrice.log10 ~ Square.Feet.log10 + Neighborhood + 
##     0, data = house)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.83000 -0.04523  0.00652  0.05027  0.34430 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## Square.Feet.log10    0.63756    0.01359   46.91   &lt;2e-16 ***
## NeighborhoodBrDale   3.08012    0.04430   69.52   &lt;2e-16 ***
## NeighborhoodBrkSide  3.11921    0.04257   73.27   &lt;2e-16 ***
## NeighborhoodClearCr  3.24736    0.04580   70.90   &lt;2e-16 ***
## NeighborhoodCollgCr  3.27724    0.04324   75.79   &lt;2e-16 ***
## NeighborhoodCrawfor  3.24288    0.04461   72.69   &lt;2e-16 ***
## NeighborhoodEdwards  3.11787    0.04256   73.26   &lt;2e-16 ***
## NeighborhoodGilbert  3.23263    0.04405   73.38   &lt;2e-16 ***
## NeighborhoodIDOTRR   3.03372    0.04252   71.35   &lt;2e-16 ***
## NeighborhoodMeadowV  3.05362    0.04333   70.48   &lt;2e-16 ***
## NeighborhoodMitchel  3.21708    0.04298   74.85   &lt;2e-16 ***
## NeighborhoodNAmes    3.17928    0.04226   75.23   &lt;2e-16 ***
## NeighborhoodNoRidge  3.34479    0.04717   70.91   &lt;2e-16 ***
## NeighborhoodNridgHt  3.39963    0.04505   75.47   &lt;2e-16 ***
## NeighborhoodNWAmes   3.21758    0.04434   72.57   &lt;2e-16 ***
## NeighborhoodOldTown  3.07508    0.04288   71.71   &lt;2e-16 ***
## NeighborhoodSawyer   3.18044    0.04214   75.47   &lt;2e-16 ***
## NeighborhoodSawyerW  3.21723    0.04400   73.11   &lt;2e-16 ***
## NeighborhoodSomerst  3.30987    0.04393   75.34   &lt;2e-16 ***
## NeighborhoodStoneBr  3.39612    0.04609   73.69   &lt;2e-16 ***
## NeighborhoodSWISU    3.08713    0.04508   68.48   &lt;2e-16 ***
## NeighborhoodTimber   3.31935    0.04502   73.73   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.08683 on 2812 degrees of freedom
## Multiple R-squared:  0.9997, Adjusted R-squared:  0.9997 
## F-statistic: 4.659e+05 on 22 and 2812 DF,  p-value: &lt; 2.2e-16</code></pre>
<div id="predictions" class="section level3 hasAnchor" number="13.2.1">
<h3><span class="header-section-number">13.2.1</span> Predictions<a href="multiple-regression-models.html#predictions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>By including the neighborhood information we got a much improved <span class="math inline">\(R^2\)</span> value. This will improve the precision of our predictions. Here is a predicted selling price interval for our 2000 sqft house in the BrkSide neighborhood.</p>
<div class="sourceCode" id="cb556"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb556-1"><a href="multiple-regression-models.html#cb556-1" aria-hidden="true" tabindex="-1"></a>predict.sales <span class="ot">=</span> <span class="fu">predict</span>(mlm.house.neigh, <span class="fu">data.frame</span>(<span class="at">Square.Feet.log10 =</span> <span class="fu">c</span>(<span class="fu">log10</span>(<span class="dv">2000</span>)),</span>
<span id="cb556-2"><a href="multiple-regression-models.html#cb556-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">Neighborhood =</span> <span class="fu">c</span>(<span class="st">&quot;BrkSide&quot;</span>)), <span class="at">interval =</span> <span class="st">&quot;predict&quot;</span>, <span class="at">level =</span> <span class="fl">0.95</span>)</span>
<span id="cb556-3"><a href="multiple-regression-models.html#cb556-3" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(<span class="dv">10</span><span class="sc">^</span>predict.sales)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 167425.1 112895.5 248292.9</code></pre>
</div>
</div>
<div id="interactions-between-variables" class="section level2 hasAnchor" number="13.3">
<h2><span class="header-section-number">13.3</span> Interactions between Variables<a href="multiple-regression-models.html#interactions-between-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Notice that when we formed our house price model with the neighborhoods included we allowed the y-intercept to change with the neighborhood. This means each neighborhood is allowed to have a different default price. However, we had only one slope variable which gives how the square footage effects the sales price. However, in general we might want to allow each neighborhood to have its own slope variable.</p>
<p>This is called an <strong>interaction</strong>. We want to allow the sqft and neighborhood variables to interact. Perhaps for some neighborhoods adding square footage changes the prices differently.</p>
<div class="sourceCode" id="cb558"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb558-1"><a href="multiple-regression-models.html#cb558-1" aria-hidden="true" tabindex="-1"></a>mlm.house.neigh.interact <span class="ot">=</span> <span class="fu">lm</span>(SalePrice.log10 <span class="sc">~</span> Square.Feet.log10 <span class="sc">+</span> Neighborhood <span class="sc">+</span></span>
<span id="cb558-2"><a href="multiple-regression-models.html#cb558-2" aria-hidden="true" tabindex="-1"></a>    Neighborhood<span class="sc">:</span>Square.Feet.log10, <span class="at">data =</span> house)</span>
<span id="cb558-3"><a href="multiple-regression-models.html#cb558-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mlm.house.neigh.interact)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = SalePrice.log10 ~ Square.Feet.log10 + Neighborhood + 
##     Neighborhood:Square.Feet.log10, data = house)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.84064 -0.04148  0.00381  0.04699  0.35560 
## 
## Coefficients:
##                                        Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)                            3.219434   0.870926   3.697 0.000223 ***
## Square.Feet.log10                      0.591796   0.286071   2.069 0.038666 *  
## NeighborhoodBrkSide                   -0.528163   0.889396  -0.594 0.552664    
## NeighborhoodClearCr                    0.754395   0.955822   0.789 0.430026    
## NeighborhoodCollgCr                   -0.315067   0.880549  -0.358 0.720515    
## NeighborhoodCrawfor                   -0.585662   0.901731  -0.649 0.516078    
## NeighborhoodEdwards                    0.061167   0.880532   0.069 0.944624    
## NeighborhoodGilbert                    0.183227   0.913648   0.201 0.841069    
## NeighborhoodIDOTRR                    -0.646000   0.890607  -0.725 0.468299    
## NeighborhoodMeadowV                    0.625649   0.933953   0.670 0.502982    
## NeighborhoodMitchel                    0.682963   0.892957   0.765 0.444435    
## NeighborhoodNAmes                      0.466131   0.877410   0.531 0.595282    
## NeighborhoodNoRidge                   -1.363954   0.966659  -1.411 0.158357    
## NeighborhoodNridgHt                   -1.102949   0.897900  -1.228 0.219413    
## NeighborhoodNWAmes                     0.205433   0.898307   0.229 0.819127    
## NeighborhoodOldTown                    0.015697   0.877699   0.018 0.985732    
## NeighborhoodSawyer                     0.776898   0.889801   0.873 0.382676    
## NeighborhoodSawyerW                   -0.247425   0.891514  -0.278 0.781391    
## NeighborhoodSomerst                   -0.733158   0.905397  -0.810 0.418145    
## NeighborhoodStoneBr                   -1.150578   0.922099  -1.248 0.212216    
## NeighborhoodSWISU                      0.449283   0.904287   0.497 0.619344    
## NeighborhoodTimber                    -0.501458   0.948561  -0.529 0.597090    
## Square.Feet.log10:NeighborhoodBrkSide  0.185106   0.292021   0.634 0.526211    
## Square.Feet.log10:NeighborhoodClearCr -0.179200   0.310955  -0.576 0.564467    
## Square.Feet.log10:NeighborhoodCollgCr  0.163853   0.289006   0.567 0.570791    
## Square.Feet.log10:NeighborhoodCrawfor  0.234854   0.295114   0.796 0.426211    
## Square.Feet.log10:NeighborhoodEdwards -0.006772   0.289113  -0.023 0.981313    
## Square.Feet.log10:NeighborhoodGilbert -0.007319   0.298770  -0.024 0.980459    
## Square.Feet.log10:NeighborhoodIDOTRR   0.196304   0.292466   0.671 0.502148    
## Square.Feet.log10:NeighborhoodMeadowV -0.217181   0.307199  -0.707 0.479643    
## Square.Feet.log10:NeighborhoodMitchel -0.174923   0.293018  -0.597 0.550575    
## Square.Feet.log10:NeighborhoodNAmes   -0.117831   0.288129  -0.409 0.682607    
## Square.Feet.log10:NeighborhoodNoRidge  0.485526   0.311714   1.558 0.119441    
## Square.Feet.log10:NeighborhoodNridgHt  0.437299   0.293726   1.489 0.136653    
## Square.Feet.log10:NeighborhoodNWAmes  -0.018729   0.294144  -0.064 0.949236    
## Square.Feet.log10:NeighborhoodOldTown -0.005403   0.288173  -0.019 0.985043    
## Square.Feet.log10:NeighborhoodSawyer  -0.221166   0.292213  -0.757 0.449195    
## Square.Feet.log10:NeighborhoodSawyerW  0.122714   0.292239   0.420 0.674583    
## Square.Feet.log10:NeighborhoodSomerst  0.303330   0.296346   1.024 0.306129    
## Square.Feet.log10:NeighborhoodStoneBr  0.451543   0.300665   1.502 0.133258    
## Square.Feet.log10:NeighborhoodSWISU   -0.136760   0.296066  -0.462 0.644172    
## Square.Feet.log10:NeighborhoodTimber   0.232207   0.308875   0.752 0.452245    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.08441 on 2792 degrees of freedom
## Multiple R-squared:  0.7794, Adjusted R-squared:  0.7762 
## F-statistic: 240.6 on 41 and 2792 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We now have a huge number of coefficients to interpret for our model. However, just like before the neighborhood ones are <strong>dummy variables</strong> (either 1 or 0). Therefore our model take the form:
<span class="math display">\[ \log_{10}(SP_N)=\alpha+\beta_N+(\beta+\beta_N)\log_{10}(SQFT)\]</span>
where the <span class="math inline">\(N\)</span> subscripts mean that parameter depends on the particular neighborhood. For example, the best-fit model for the âTimber neighborhoodâ would be:
<span class="math display">\[ \log_{10}(SP_N)=3.2194-0.501458+(0.591796+0.232207)\log_{10}(SQFT)\]</span>
Notice that including this interaction term buys us a slight increase in the <span class="math inline">\(R^2\)</span> value for the model. However, our model is much more complex. This is a usual trade-off (complexity versus predictive power).</p>
<p>The topic of how to choose the best model is an entire mathematics discipline called <strong>model selection</strong>. Naturally, this can be quite a complicated topic. The general guide to model selection is a Goldilocks principle: <strong>Build a model which is just detailed enough to match your application, and no more complex.</strong></p>
</div>
<div id="some-pitfalls-in-multiple-regression" class="section level2 hasAnchor" number="13.4">
<h2><span class="header-section-number">13.4</span> Some Pitfalls in Multiple Regression<a href="multiple-regression-models.html#some-pitfalls-in-multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><p><strong>Core assumptions:</strong> The assumptions of linear regression carry over to multiple regression. Significant violations of the assumptions of linearity, independence of errors, normality of errors, or constant variance can all cause problems just like simple regression. We can check for these using our diagnostic plots.</p></li>
<li><p><strong>Multicollinearity:</strong> This occurs when two or more explanatory variables are moderately to highly correlated. It complicates the model interpretations and can skew the statistics for it. It can be avoided by proper EDA.</p></li>
<li><p><strong>Over-fitting:</strong> Build as simple a model as possible to describe your data. If you include every possible explanatory variable in your model you will begin to model the random effects in your data instead of the actual trends. This builds unnecessarily complex models which make incorrect predictions: not a good combination.</p></li>
</ol>

<div class="warning">
Avoid including explanatory variables in your model which do not improve the fit by a practically significant amount. If you add a redundant explanatory variables this will be the case (only a small improvement).
</div>
</div>
<div id="homework-11" class="section level2 hasAnchor" number="13.5">
<h2><span class="header-section-number">13.5</span> Homework<a href="multiple-regression-models.html#homework-11" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="concept-questions-10" class="section level3 hasAnchor" number="13.5.1">
<h3><span class="header-section-number">13.5.1</span> Concept Questions<a href="multiple-regression-models.html#concept-questions-10" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>(True/False) When building multiple regression models we should include every possible explanatory variable we have available.</li>
<li>(True/False) Over-fitting occurs when we include to many explanatory variables in our model</li>
<li>(True/False) Under-fitting occurs when some key explanatory variables are left out of our model.</li>
<li>(True/False) An over-fit model may describe the data used to fit it very closely (high goodness of fit) but generate poor predictive estimates</li>
<li>(True/False) Multicollinearity is a good thing when we are considering whether to include an additional explanatory variable in our model.</li>
</ol>
</div>
<div id="practice-problems-11" class="section level3 hasAnchor" number="13.5.2">
<h3><span class="header-section-number">13.5.2</span> Practice Problems<a href="multiple-regression-models.html#practice-problems-11" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>Suppose I am building a linear model to predict the college GPA (C) of incoming students using data from their college applications.</p>
<ul>
<li>I begin with a simple regression using their high school GPA (H). Thus my model looks like <span class="math display">\[C=\alpha+\beta_1 H.\]</span> What are the interpretations of the slope and intercept values of this model?</li>
<li>Suppose I decide to include the students SAT scores (S) as well. Now my model reads <span class="math display">\[C=\alpha+\beta_1 H+ \beta_2 S.\]</span> How can I interpret the coefficients of this model? What conditions should I check before including this extra explanatory variable in my model?</li>
<li>Suppose the SAT score variable turns out to be useless in predicting college GPA and I decide to remove it. I now add a variable (A) which is zero for students who were not athletes in high school and 1 for those who played some sport. Thus my model is <span class="math display">\[C=\alpha+\beta_1 H+\beta_2 A.\]</span> How can I interpret the coefficients for this model?</li>
</ul></li>
</ol>
</div>
<div id="advanced-problems-11" class="section level3 hasAnchor" number="13.5.3">
<h3><span class="header-section-number">13.5.3</span> Advanced Problems<a href="multiple-regression-models.html#advanced-problems-11" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li><p>Load the <code>kidiq</code> data set from the class R package. This data set contains the iq scores for children and characteristics of the mothers. We will perform a multiple regression analysis on this data set with the <code>kid_score</code> column as the response variable and the other columns as potential explanatory variables.</p>
<ul>
<li>Classify the statistical variable types for the explanatory variables (categorical, numeric, etc)</li>
<li>Form a simple regression using the explanatory variable <code>mom_iq</code>? Interpret the results. How precise is the fit?
how can we interpret the slope and intercept values?</li>
<li>Form a simple regression with <em>just</em> the <code>mom_hs</code> variable as the explanatory variable. Intepret the slope and intercept in this case. Does this variable influence the value of the <code>kid_score</code> column?<br />
</li>
<li>Form a muliple regression using both the <code>mom_iq</code> and <code>mom_hs</code> columns as explanatory variables. Interpret the meaning of the slope and intercept in this case. How does this change the fit of our model?</li>
</ul></li>
<li><p>Load the <code>NBA_Draft_Data</code> from the class R Package. We will use using the columns PTS, Pick.Number and Pos. The PTS column gives the average PPG for that player over the course of their career.</p>
<ul>
<li>Conduct a simple regression analysis using the response variable PTS and the explanatory variable Pick.Number. Interpret the results. What do the intercept and slope parameters tell you in this case?</li>
<li>Add the explanatory variable <code>Pos</code> to your model. How does this change your fit.</li>
<li>Interpret the model what do the coefficients mean?</li>
</ul></li>
<li><p>Load the videoGameSales data set in R (again). Last chapter you looked for a relationship between the <code>genre</code> column and the <code>Global_Sales</code> column, now we will add the <code>Critic_Score</code> column as well.</p>
<ul>
<li>Make the appropriate graphical representations to look for relationships between the two sets of variables.</li>
<li>Build a regression model of your system. Write down the model form and what each of the slopes and the intercepts mean. What can you conclude based on your model?</li>
</ul></li>
</ol>

</div>
</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="regression-with-categorical-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hypothesis-testing-one-sample.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/12-MultipleRegression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["statsbook.pdf", "statsbook.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
},
"collapse": "section"
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
